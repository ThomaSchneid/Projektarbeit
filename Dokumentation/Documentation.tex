\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage{float}
\usepackage{color}
\usepackage[T1]{fontenc}
\usepackage{xcolor}
%\usepackage{listings}
\usepackage{pythonhighlight}


%New commands
\newcommand{\tief}{\textsubscript}
\newcommand{\hoch}{\textsuperscript}
\newcommand{\nl}{\newline}
\newcommand{\formelbox}[1]{\centerline{\fbox{#1}}}

\begin{document}
	\title{Focus peaking - can edge detection improve the performance of current algorithms?}
	\author{Thomas Schneider \\ Matrikel-Nr: 60482 \\ Elektro- und Informationstechnik \\ Hochschule Karlsruhe}
	\onecolumn
	\maketitle
	\tableofcontents
	\twocolumn
	
	\section{Motivation/Einleitung}
	
	\begin{center}
		\textcolor{red}{\textbf{TODO}}
	\end{center}
	
	\section{Mathematische Grundlagen}

		\subsection{Gauß Filter}
	
		Der Gauß Filter ist ein linearer Filter, welcher in der Bildverarbeitung zur Glättung des Bildes und Verminderung von Rauschen, vor allem weißem,  verwendet. Feinere Strukturen des Bildes gehen hierbei verloren, wobei gröbere erhalten bleiben.
		Ein Gaußscher Filterkern der Größe (2k + 1)$\times$(2k + 1) kann mit
		\medbreak
		\formelbox{H\tief{ij} = $\frac{1}{2\pi\sigma\hoch{2}}$ * $\mathrm{e}$\hoch{-$\frac{(i - (k + 1))\hoch{2} + (j - (k + 1))\hoch{2}}{2\sigma\hoch{2}}$}}
		\medbreak
		berechnet werden. \nl
		In Python wird der Gauß Kern folgendermaßen realisiert:
		
		\begin{python}
			def gaussian_kernel(size, sigma=1):
				size = int(size) // 2   # c1 * 1
				x, y = np.mgrid[-size:size + 1,
				-size:size + 1]     # c2 * 1
				normal = 1 / 
				(2.0 * np.pi * sigma ** 2)     # c3 * 1
				g = np.exp(-((x ** 2 + y ** 2) / 
				(2.0 * sigma ** 2))) * normal      # c4 * 1
				
				return g
		\end{python}		
	
		\subsection{Sobel Operator}
	
		Der Sobel Operator besteht aus zwei 3$\times$3 Faltungskernen, wobei ein Kern dem jeweils anderen um 90$\circ$ gedreht.
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.6\linewidth] {../Bilder/sobel_operator}
			\caption{\textit{Links der Faltungskern für die X- und rechts für die Y-Richtung.}}
		\end{figure}
	
		Für jedes Pixel werden die Komponenten der Matrix aufsummiert um den Grauwert zu erhalten.
		
		In Python realisieren wir den Sobel Filter folgendermaßen:
		
		\begin{python}
			def sobel_filter(img):
				Gx = np.array([[-1, 0, 1], [-2, 0, 2],
				[-1, 0, 1]], np.float32)     #c5 * 1
				Gy = np.array([[1, 2, 1], [0, 0, 0],
				[-1, -2, -1]], np.float32)     #c5 * 1
				
				Ix = ndimage.filters.convolve(img, Gx).
				astype(float)    # c6 * 1
				Iy = ndimage.filters.convolve(img, Gy).
				astype(float)    # c6 * 1
				
				G = np.hypot(Ix, Iy)    # c7 * 1
				G = G / G.max() * 255   # c8 * 1
				theta = np.arctan(Iy, Ix)   # c9 * 1
		
				return G, theta
		\end{python}
	
		\subsection{Non Maximum Suppression}
	
		Die Non Maximum Suppression Technik wird angewendet um bereits gefundene Intensitätsmaxima (Kanten) erneut zu prüfen und diese auszudünnen. Hierfür durchläuft der Algorithmus jedes gefundene Kantenpixel und vergleicht, basierend auf dem Gradienten des jeweiligen Pixels, die entsprechenden Nachbarpixel. Sollte eines der Nachbarpixel einen höheren Grauwert als das aktuelle Pixel aufweisen, wird der Grauwert des aktuellen Pixels auf 0 gesetzt. Bildlich kann man sich die Technik folgendermaßen vorstellen
	
		\begin{figure}[H]
			\centering
			\includegraphics[width=1\linewidth] {../Bilder/nms_how_to}
			\caption{\textit{Darstellung der Non Maximum Suppression Technik}}
		\end{figure}

		Schauen wir uns nun das untere, rot umrahmte Pixel etwas genauer an. Die Richtung der Kante wird hier durch den blauen Pfeil symbolisiert und und entspricht einem Winkel von $\frac{\pi}{2}$ (90°).
	
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.7\linewidth] {../Bilder/nms_inspect_pixel}
			\caption{\textit{Nähere Betrachtung eines einzigen Pixels}}
		\end{figure}
	
		Die Richtung der Kante wird durch den grünen Pfeil dargestellt und verläuft vertikal von oben nach unten. Der Algorithmus prüft nun, ob die Pixel ober- und unterhalb (im Bild blau markiert) des ausgewählten Pixels (rot im Bild markiert) einen höheren Intensitätswert aufweisen. In unserem Beispiel ist der Intensitätswert des unteren Pixels (i + 1, j) höher als der der anderen Beiden (das untere Pixel hat einen Intensitätswert von 255, da es weiß ist). Der Intensitätswert des aktuellen Pixels wird nun auf 0 gesetzt. Hätte keines der beiden anderen Pixel einen höheren Intensitätswert, würde der aktuelle Wert beibehalten werden.\nl
		Jedes Pixel hat also 2 Hauptkriterien, die Gradientenrichtung und den Intensitätswert. Die Non Maximum Suppression nutzt diese beiden Merkmale und führt folgende Schritte durch:
	
		\begin{itemize}
			\item Eine Matrix mit nullen der gleichen Größe der Gradientenmatrix erstellen
			\item Kantenrichtung anhand der Gradientenmatrix erkennen
			\item Prüfen ob Pixel entlang der Kantenrichtung einen höheren Intensitätswert als das aktuelle Pixel haben
			\item Das mit dem Non Maximum Suppression Algorithmus bearbeitete Bild zurückgeben
		\end{itemize}

		Den Non Maximum Suppression Algorithmus realisieren wir durch folgenden Python Code:
	
		\begin{python}
			def non_max_suppression(img, D):
				M, N = img.shape    # c10 * 1
				Z = np.zeros((M, N))    # c11 * 1
				angle = D * 180. / np.pi    # c12 * 1
				angle[angle < 0] += 180     # c13 * 1
				
				for i in range(1, M - 1):   # c14 * (M - 2)
					for j in range(1, N - 1):   
					# c15 * ((M - 2) * (N - 2))
						try:    # c16 * ((M - 2) * (N - 2))
							q = 255    # c17 * ((M - 2) * (N - 2))
							r = 255    # c17 * ((M - 2) * (N - 2))
							
							# angle 0
							if (0 <= angle[i, j] < 22.5) or 
							(157.5 <= angle[i, j] <= 180):  
							# c18 * ((M - 2) * (N - 2))
								q = img[i, j + 1]   # c19 * A0
								r = img[i, j - 1]   # c19 * A0
							# angle 45
							elif 22.5 <= angle[i, j] < 67.5:    
							# c20 * (((M - 2) * (N - 2)) - A0)
								q = img[i + 1, j - 1]   # c19 * A45
								r = img[i - 1, j + 1]   # c19 * A45
							# angle 90
							elif 67.5 <= angle[i, j] < 112.5:   
							# c20 * (((M - 2) * (N - 2)) - 
							# A0 - A45)
								q = img[i + 1, j]   # c19 * A90
								r = img[i - 1, j]   # c19 * A90
							# angle 135
							elif 112.5 <= angle[i, j] < 157.5:  
							# c20 * (((M - 2) * (N - 2)) - 
							# A0 - A45 - A90)
								q = img[i - 1, j - 1]   # c19 * A135
								r = img[i + 1, j + 1]   # c19 * A135
							
							if (img[i, j] >= q) and 
							(img[i, j] >= r):   
							# c21 * ((M - 2) * (N - 2))
								Z[i, j] = img[i, j]     # c22 * Y
							else:
								Z[i, j] = 0     # c23 * (((M - 2) * 
								# (N - 2)) - Y)
						
						except IndexError as e:     # c24 * 0
							pass    # c24 * 0
				return Z
		\end{python}
	
		\subsection{Double threshold}
	
		Der double threshold Filter unterteilt unser Bild in 3 Arten von Pixeln
	
		\begin{itemize}
			\item \textbf{Starke Pixel}
			\begin{itemize}
				\item Pixel, deren Intensitätswert hoch genug ist, dass wir uns sicher sein können, dass sie ein Teil der finalen Kante sind.
			\end{itemize}
			\item \textbf{Schwache Pixel}
			\begin{itemize}
				\item Pixel, deren Intensitätswert nicht hoch genug ist um als starkes Pixel eingestuft zu werden, allerdings hoch genug ist um nicht als unsignifikant für die Kantenerkennung zu sein.
			\end{itemize}
			\item \textbf{Andere Pixel}
			\begin{itemize}
				\item Alle Pixel, welche keine der anderen beiden Bedingungen erfüllen.
			\end{itemize}
		\end{itemize}

		Es wird eine Obergrenze (high threshold) und eine Untergrenze (low threshold) für die Intensitätswerte festgelegt. Ist der Intensitätswert eines Pixels höher als oder gleich der Obergrenze, wird es als starkes Pixel markiert, der Intensitätswert also auf 255 gesetzt. Befindet sich der Intensitätswert des Pixels zwischen Ober- und Untergrenze, wird es als schwaches Pixel markiert. Sollte der Intensitätswert des Pixels kleiner als die Untergrenze sein, wird er auf 0 gesetzt. \nl
		Die beiden Schwellenwerte werden abhängig vom Eingangsbild berechnet, in unserem Beispiel durch den Faktor 0.05 für die untere und 0.09 für die obere Schwelle. In Python setzen wir die double threshold Funktion folgendermaßen um:
	
		\begin{python}
			def double_threshold(img, lowRatio=0.05, 
								 highRatio=0.09):
 				highThreshold = img.max() * highRatio   
				# c26 * 1
				lowThreshold = highThreshold * lowRatio     
				# c27 * 1
				
				M, N = img.shape     # c10 * 1
				res = np.zeros((M, N))  # c11 * 1
				
				strong = 255  # c17 * 1
				weak = 25     # c17 * 1
				zero = 0      # c17 * 1
				
				strong_i, strong_j = np.
				where(img >= highThreshold)     # c28 * 1
				zeros_i, zeros_j = np.
				where(img < lowThreshold)     # c28 * 1
				weak_i, weak_j = np.where(
				(img <= highThreshold) & 
				(img >= lowThreshold))   # c29 * 1
				
				res[strong_i, strong_j] = strong    
				# c30 * 1
				res[weak_i, weak_j] = weak      # c30 * 1
				res[zeros_i, zeros_j] = zero    # c30 * 1
			
				return res
		\end{python}

		\subsection{Kantenverfolgung durch Hysterese}
		
		Durch eine Hysterese wird festgelegt, ab welcher Kantenstärke ein Pixel zu einer Kante gehört. Mithilfe zweier Schwellwerte T\tief{1} < T\tief{2} wird jedes Pixel eines Bildes überprüft. Sobald ein Pixel einen Intensitätswert über T\tief{2} hat, wird diesem Pixel gefolgt und jedes Pixel entlang der so gefundenen Kante, dessen Intensitätswert größer T\tief{1} ist, als Element dieser Kante markiert.
		
		Wir realisieren unsere Hysterese Funktion in Python folgendermaßen:
		
		\begin{python}
			def hysteresis(img, weak, strong=255):
 				M, N = img.shape    # c10 * 1
				for i in range(1, M - 1):   # c14 * (M - 2)
					for j in range(1, N - 1):   
					# c15 * ((M - 2) * (N - 2))
						if img[i, j] == weak:   
						# c31 * ((M - 2) * (N - 2))
							try:    
							# c16 * (((M - 2) * (N - 2)) - Z)
								if ((img[i + 1, j - 1] == strong) or 
								(img[i + 1, j] == strong) or 
								(img[i + 1, j + 1] == strong) or 
								(img[i, j - 1] == strong) or 
								(img[i, j + 1] == strong) or 
								(img[i - 1, j - 1] == strong) or 
								(img[i - 1, j] == strong) or 
								(img[i - 1, j + 1] == strong)):  
								# c32 * (((M - 2) * (N - 2)) - Z)
									img[i, j] = strong  
									# c33 * (((M - 2) * 
									# (N - 2)) - Z - S)
								else:
									img[i, j] = 0   
									# c23 * (((M - 2) * 
									# (N - 2)) - Z - T)
							except IndexError as e:     
							# c24 * 0
								pass    # c25 * 0
				return img
		\end{python}
	
	\section{Laufzeiteffizienz eines Algorithmus}
	
	Nun wollen wir die Laufzeit des genannten Algorithmus betrachten. Hierzu zählen wir für eine gegebene Eingabe alle Anweisungen x mit einer Zeit t\tief{x}, welche von der Art von x abhängig ist. Folgende Annahmen setzen wir voraus: \nl
	
	\begin{itemize}
		\item Das Ausführen einer Zeile Code benötigt einen konstanten Zeitaufwand
		\item Verschiedene Zeilen (verschiedene Operationen) benötigen einen unterschiedlichen Zeitaufwand
	\end{itemize}
	
	Der benötigte, konstante Zeitaufwand, welchen eine Zeile z also benötigt, wird mit c\tief{x} bezeichnet.
	Im vorherigen Abschnitt ist in den Kommentaren des Python Codes bereits der jeweilige Zeitaufwand jeder Zeile vermerkt.
	Im Folgenden werden die Laufzeiten der einzelnen Funktionen sowie im Abschluss des gesamten Canny Algorithmus berechnet.\nl
	Zusätzlich betrachten wir - sofern möglich - den jeweils schlechtesten und besten Fall.\nl
	
		\subsection{Gauß Filter}

		Die Kosten für den Gauß Filter ergibt sich der Laufzeitaufwand hiermit zu: \nl
	
		\formelbox{ T(n)\tief{Gauß} = c\tief{1} + c\tief{2} + c\tief{3} + c\tief{4} }
		
		Da wir hier jede Zeile einmal durchlaufen müssen ist der schlechteste Fall gleich dem besten Fall.

		\subsection{Sobel Filter}

		Der Sobel Filter hat ähnlich zum Gauß Filter einen geringen Laufzeitaufwand im Vergleich zum Gesamtaufwand:\nl
	
		\formelbox{ T(n)\tief{Sobel} = (c\tief{5} + c\tief{6}) * 2 + c\tief{7} + c\tief{8} + c\tief{9} }
	
		Der Sobel Filter ist nur vom jeweiligen Eingangsbild abhängig, jede Zeile muss einmal durchlaufen werden. Je größer das Bild, desto größer auch der Rechenaufwand. Auch hier entspricht der schlechteste Fall gleich dem besten Fall.
	
		\subsection{Non Maximum Supression}
	
		Den größten Rechenaufwand beansprucht die Non Maximum Suppression. Hier ergibt sich der benötigte Laufzeitaufwand zu: \nl
	
		\formelbox{\parbox{0.5\textwidth}{
			\begin{center}
				T(n)\tief{nms} = c\tief{10} + c\tief{11} + c\tief{12} + c\tief{13} + c\tief{14} * (M - 2) + \\
				(c\tief{15} + c\tief{16} + 2 * c\tief{17} + c\tief{18} + 3 * c\tief{20} + c\tief{21} + \\
				c\tief{23}) * ((M - 2) * (N - 2)) + \\
				(2 * c\tief{19} - 9 * c\tief{20}) * A0 + \\
				(2 * c\tief{19} - 6 * c\tief{20}) * A45 + \\
				(2 * c\tief{19} - 3 * c\tief{20}) * A90 + \\
				c\tief{19} * 2 * A135 + \\ 
				(c\tief{22} - c\tief{23}) * Y
			\end{center}
		}}
		
%		Wir unterscheiden den Laufzeitaufwand nun für den best- sowie den schlechtmöglichsten Fall: \nl
%		
%			\subsubsection{Bestmöglicher Fall}
%		
%			Im Bestmöglichen Fall liegt jeder Winkel zwischen 0° und 22.5° oder 157.5° und 180° und der Intensitätswert eines jeden Pixels des Bildes ist höher als der seiner Nachbarn in Gradientenrichtung. In diesem Fall kann man mit folgenden Annahmen Rechnen:\nl
%		
%			\formelbox{\parbox{0.5\textwidth}{
%			\begin{center}
%				A0 = Y = ((M - 2) * (N - 2)); \\
%				A45 = A90 = A135 = 0; \\			
%			\end{center}
%			}}
%			
%			Womit sich der Laufzeitaufwand vereinfacht zu: \nl
%			
%			\formelbox{\parbox{0.5\textwidth}{
%				\begin{center}
%					T(n)\tief{nms} = c\tief{10} + c\tief{11} + c\tief{12} + c\tief{13} + c\tief{14} * (M - 2) + \\
%					(c\tief{15} + c\tief{16} + 2 * c\tief{17} + c\tief{18} + 2 * c\tief{19} + \\
%					c\tief{21} + c\tief{22}) * ((M - 2) * (N - 2)) \\
%				\end{center}
%			}}
%		
%			\subsubsection{Schlechtester Fall}
%			
%			Im schlechtesten Fall liegt jeder Winkel zwischen 112.5° und 157.5° und der Intensitätswert eines jeden Pixels des Bildes ist niedriger als der seiner Nachbarn in Gradientenrichtung. In diesem Fall kann man mit folgenden Annahmen Rechnen:\nl
%			
%			\formelbox{\parbox{0.5\textwidth}{
%					\begin{center}
%						A135 = ((M - 2) * (N - 2)); \\
%						A0 = A45 = A90 = Y = 0; \\			
%					\end{center}
%			}}
%		
%			Womit sich der worst-case Laufzeitaufwand folgendermaßen gestaltet:\nl
%			
%			\formelbox{\parbox{0.5\textwidth}{
%				\begin{center}
%					T(n)\tief{nms} = c\tief{10} + c\tief{11} + c\tief{12} + c\tief{13} + c\tief{14} * (M - 2) + \\
%					(c\tief{15} + c\tief{16} + 2 * c\tief{17} + c\tief{18} + 2 * c\tief{19} + 3 * c\tief{20} + c\tief{21} + \\
%					c\tief{23}) * ((M - 2) * (N - 2)) \\
%				\end{center}
%			}}
		
		\subsection{Double threshold}
		
		Die double Threshold Methode beansprucht folgenden Laufzeitaufwand: \nl
	
		\formelbox{\parbox{0.5\textwidth}{
			\begin{center}
				T(n)\tief{double threshold} = c\tief{10} + c\tief{11} + 3 * c\tief{17} + \\
				c\tief{26} + c\tief{27} + 2 * c\tief{28} + c\tief{29} + 3 * c\tief{30}
			\end{center}
		}}
		
		\subsection{Hysterese}
	
		Letztendlich noch der Laufzeitaufwand der Hysterese mit: \nl
	
		\formelbox{\parbox{0.5\textwidth}{
			\begin{center}
				T(n)\tief{hysterese} = c\tief{10} + c\tief{14} * (M - 2) + \\
				(c\tief{15} + c\tief{16} + c\tief{23} + c\tief{31} + c\tief{32} + c\tief{33}) * ((M - 2) * (N - 2)) - \\
				Z * (c\tief{15} + c\tief{23} + c\tief{32} + c\tief{33}) - \\
				S * c\tief{33} - T * c\tief{23} \\
			\end{center}
		}}

		\subsection{Komplette Laufzeit}

		Für die komplette Laufzeit T(n)\tief{Canny} des Algorithmus ergibt sich somit zu:
	
		\formelbox{\parbox{0.5\textwidth}{
			\begin{center}
				T(n)\tief{Canny} = \\
				c\tief{1} + c\tief{2} + c\tief{3} + c\tief{4} +	c\tief{5} * 2 + c\tief{6} * 2 + c\tief{7} + \\
				c\tief{8} + c\tief{9} + c\tief{10} * 3 + c\tief{11} * 2 + c\tief{12} + c\tief{13} + \\
				c\tief{14} * 2 * (M - 2) + c\tief{15} * (2 * ((M - 2) * (N - 2)) - Z) + \\
				c\tief{16} * 2 * ((M - 2) * (N - 2)) + c\tief{17} * 6 * ((M - 2) * (N - 2)) + \\
				c\tief{18} * ((M - 2) * (N - 2)) + \\
				c\tief{19} * 2 * (A0 + A45 + A90 + A135) + \\
				c\tief{20} * (-9 * A0 -6 * A45 -3 * A90 + 3 * ((M - 2) * (N - 2))) + \\
				c\tief{21} * ((M - 2) * (N - 2)) + c\tief{22} * Y + \\
				c\tief{23} * (2 * ((M - 2) * (N - 2)) - T - Y - Z) + \\
				c\tief{26} + c\tief{27} + c\tief{28} * 2 + c\tief{29} + c\tief{30} * 3 + \\
				c\tief{31} * ((M - 2) * (N - 2)) + c\tief{32} * (((M - 2) * (N - 2)) - Z) + \\
				c\tief{33} * (((M - 2) * (N - 2)) - Z - S) \\
			\end{center}
		}}
	
		Mit\nl
	 
		\formelbox{\parbox{0.5\textwidth}{
			\begin{center}
				A0 + A45 + A90 + A135 = ((M - 2) * (N - 2)); \\
				Z - T = S; \\
				Z - S = T; \\
				((M - 2) * (N - 2)) $\widehat{=}$ L; \\
			\end{center}
	
		}}

		Kann man die Gleichung folgendermaßen vereinfachen:\nl

		\formelbox{\parbox{0.5\textwidth}{
			\begin{center}
				T(n)\tief{Canny} = \\
				c\tief{1} + c\tief{2} + c\tief{3} + c\tief{4} +	c\tief{5} * 2 + c\tief{6} * 2 + c\tief{7} + \\
				c\tief{8} + c\tief{9} + c\tief{10} * 3 + c\tief{11} * 2 + c\tief{12} + c\tief{13} + \\
				c\tief{14} * 2 * (M - 2) + c\tief{15} * (2 * L - Z) + \\
				c\tief{16} * 2 * L + c\tief{17} * 6 * L + c\tief{18} * L + \\
				c\tief{19} * 2 * L + c\tief{20} * (-9 * A0 -6 * A45 -3 * A90 + 3 * L) + \\
				c\tief{21} * L + c\tief{22} * Y + c\tief{23} * (2 * L - Y - S) + \\
				c\tief{26} + c\tief{27} + c\tief{28} * 2 + c\tief{29} + c\tief{30} * 3 + \\
				c\tief{31} * L + c\tief{32} * L - Z) + c\tief{33} * (L - T) \\
			\end{center}
		}}
	
		L hängt hierbei von der Größe des Eingangsbildes ab. Je größer das Eingangsbild, desto größer auch L und desto mehr Laufzeitaufwand ist nötig.
		
			\subsubsection{Laufzeit im besten Fall}
			
			Im besten Fall (in welchem es trotzdem noch eine Kante im Bild gibt) kann man folgende Annahmen treffen:\nl
			
			\formelbox{\parbox{0.5\textwidth}{
					\begin{center}
						A45 = A90 = A135 = S = 0; \\
						A0 = Y = L; \\
						Z + T = L; \\
					\end{center}
			}}
		
			\formelbox{\parbox{0.5\textwidth}{
					\begin{center}
						T(n)\tief{Canny} = \\
						c\tief{1} + c\tief{2} + c\tief{3} + c\tief{4} +	c\tief{5} * 2 + c\tief{6} * 2 + c\tief{7} + \\
						c\tief{8} + c\tief{9} + c\tief{10} * 3 + c\tief{11} * 2 + c\tief{12} + c\tief{13} + \\
						c\tief{14} * 2 * (M - 2) + c\tief{15} * (2 * L - Z) + \\
						c\tief{16} * 2 * L + c\tief{17} * 6 * L + c\tief{18} * L + \\
						c\tief{19} * 2 * L + \\
						c\tief{21} * L + c\tief{22} * Y + \\
						c\tief{26} + c\tief{27} + c\tief{28} * 2 + c\tief{29} + c\tief{30} * 3 + \\
						c\tief{31} * L + c\tief{32} * (L - Z) + c\tief{33} * Z \\
					\end{center}
			}}	
		
			\subsubsection{Lauftzeit im schlimmsten Fall}
			
			Analog können für den schlimmsten Fall folgende Annahmen getroffen werden:\nl
			
			\formelbox{\parbox{0.5\textwidth}{
				\begin{center}
					A0 = A45 = A90 = Y = Z = T = 0; \\
					S = L; \\
				\end{center}
			}}
		
			\formelbox{\parbox{0.5\textwidth}{
				\begin{center}
					T(n)\tief{Canny} = \\
					c\tief{1} + c\tief{2} + c\tief{3} + c\tief{4} +	c\tief{5} * 2 + c\tief{6} * 2 + c\tief{7} + \\
					c\tief{8} + c\tief{9} + c\tief{10} * 3 + c\tief{11} * 2 + c\tief{12} + c\tief{13} + \\
					c\tief{14} * 2 * (M - 2) + c\tief{15} * 2 * L + c\tief{16} * 2 * L + \\
					c\tief{17} * 6 * L + c\tief{18} * L + c\tief{19} * 2 * L + \\
					c\tief{20} * 3 * L + c\tief{21} * L + c\tief{23} * L + c\tief{26} + \\
					c\tief{27} + c\tief{28} * 2 + c\tief{29} + c\tief{30} * 3 + c\tief{31} * L + \\
					c\tief{32} * L + c\tief{33} * L \\
				\end{center}
			}}
	
	\section{Kantenerkennung mit dem Canny Algorithmus}
		
		Im folgenden sind die oben genannten Schritte des Canny Algorithmus einzeln in Python realisiert und auf ein Bild angewendet.		
	
		\subsection{Noise Reduction}
	
		Kantenerkennung ist sehr anfällig für Rauschen, da die meisten und ausschlaggebendsten mathematischen Operationen auf Ableitungen basieren. Deshalb muss eventuell vorhandenes Rauschen im ersten Schritt entfernt werden.
		Hierfür wir beim Canny Algorithmus das Bild mithilfe eines Gauß Filters geglättet. Mit einem Gaußschen Kernel (hier 5x5) wird der Intensitätswert an der Stelle (i,j) durch das gewichtete Mittel der ihn umgebenden Werte ersetzt.
		Der resultierende "blurring" Effekt hängt unmittelbar mit der Wahl der Kerngröße zusammen - je größer der Kern,  desto besser ist auch der blurring Effekt. Mit steigender Kerngröße steigt jedoch auch die benötigte Rechenzeit, weshalb man hier nur einen 5x5 Kern nimmt, um bei einem ausreichend guten Ergebnis noch performant zu sein.
		
		Hier auf das Logo der Hochschule Karlsruhe angewendet erkennt man im rechten Bild eine Unschärfe gegenüber dem linken Bild.
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.8\linewidth] {../Bilder/hochschule_blur_5_5}
			\caption{\textit{Links das original und rechts unter Anwendung des Gauß Filters.}}
		\end{figure}
		
		\subsection{Gradient Calculation}
		
		In diesem Schritt wird sowohl die Intensität als auch die Richtung der Kanten durch die Berechnung des Gradienten ermittelt. Eine Kante wird durch eine merkliche Änderung der Intensität benachbarter Pixel deutlich. Um eine Kante zu erkennen ist es also am einfachsten, einen Filter anzuwenden, welcher die Änderung der Intensität in horizontaler wie vertikaler Richtung markiert.
		
		Nach Glättung des Bildes werden nun also die Ableitungen in x (horizontaler) und y (vertikaler) Richtung berechnet. Am effizientesten kann man dies durch eine Faltung des Bildes mit einem Sobel Kern berechnen.
		
		Die Intensität und Richtung berechnen sich also zu \\
		
		\formelbox{|G| = $\sqrt{I\tief{x}\hoch{2} + I\tief{y}\hoch{2}}$}
		\medbreak
		\formelbox{$\Theta$(x,y) = arctan($\frac{I\tief{y}}{I\tief{x}})$}
		\medbreak
		Bereits nach diesem Schritt hat man schon ein ziemlich gutes Ergebnis in welchem das Ursprungsbild durch Kanten hinreichend dargestellt ist. 
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.5\linewidth] {../Bilder/sobel_after_blur}
			\caption{\textit{Bild nach Anwendung des Sobel Filters}}
		\end{figure}
		
		Man erkennt allerdings, dass die Kanten noch sehr unfein, grob und breit sind. Hier kommt der dritte Schritt ins Spiel, die Non-Maximum Suppression.
		
		\subsection{Non Maximum Suppression}
		
		Die momentan noch mehr als 1 Pixel breiten Kanten werden nun mit der sogenannten Non-Maximum Suppression Technik ausgedünnt. Hierbei wird jedes Pixel durchlaufen. Abhängig vom Gradienten, welcher uns die Richtung der Kante angibt, werden die Intensitätswerte der beiden Nachbarpixel des jeweiligen Pixels mit dem Intensitätswert des aktuellen Pixels verglichen. Ist einer der beiden Nachbarwerte größer, so wird der Grauwert des aktuellen Pixels auf Null gesetzt, andernfalls bleibt er unverändert. Nach einem erfolgreichen Durchlauf wurden alle Pixel entlang der Kante mit maximalen Intensitätswerten behalten. 
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.5\linewidth] {../Bilder/nms_after_sobel}
			\caption{\textit{Bild nach Anwendung der Non Maximum Suppression}}
		\end{figure}
		
		Man kann eine deutliche Ausdünnung der Kanten erkennen, ebenso ist ersichtlich, dass die Intensitätswerte der gefundenen Pixel Kanten noch stark variieren. Mit den folgenden 2 Schritten versuchen wir das so gut als möglich zu kompensieren und die Intensitätswerte zu vereinheitlichen.
		
		\subsection{Double threshold}
		
		Durch die double threshold Funktion markieren wir nun jedes bis jetzt als Kante markiertes Pixel als starkes oder schwaches Pixel und erhalten ein Bild mit nurnoch 3 verschiedenen Intensitätswerten, 255 (starkes Pixel), 25 (schwaches Pixel) und 0 (kein Kantenpixel).
	
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.5\linewidth] {../Bilder/double_threshold_after_nms}
			\caption{\textit{Bild mit starken (weiss) und schwachen (grau) Pixeln}}
		\end{figure}
	
		\subsection{Hysteresis}
		
		Zuletzt werden noch einmal alle Pixel geprüft und falls einer der direkten Nachbarn ein starkes Pixel ist, wird das aktuelle Pixel - falls es kein starkes Pixel ist - in ein starkes Pixel umgewandelt, indem der Intensitätswert auf 255 gesetzt wird.\nl
		Wenn ein Pixel kein starkes Pixel in der Nachbarschaft hat, wird sein Intensitätswert zu  0 gesetzt.
	
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.8\linewidth] {../Bilder/no_strong_pixel_around}
			\caption{\textit{Ein Pixel ohne starkes Pixel in der Nachbarschaft}}
		\end{figure}
	
		Hat ein Pixel ein starkes Pixel in der Nachbarschaft, wird sein Intensitätswert auf 255 gesetzt, es selbst zu einem starken Pixel.
	
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.8\linewidth] {../Bilder/one_strong_pixel_around}
			\caption{\textit{Ein Pixel mit einem starken Pixel in der Nachbarschaft}}
		\end{figure}
	\section{Effizienzgewinn durch Kantenverfolgung}
	
	\subsection{Idee}
	
	Sobald eine Kante gefunden wurde ist es nicht mehr notwendig, jedes einzelne Pixel des kompletten Bildes zu überprüfen. Man kann die Kante entlang laufen und so nur die relevanten Bereiche des Bildes untersuchen, was den Rechenaufwand enorm verringert. 
	Es wurde schnell klar, dass Kantenverfolgung hier nicht zielführend ist, da es sich sehr sehr schnell im Kreis drehen kann. <- Ideen und Rechnungen zeigen.
	\begin{center}
		\textcolor{red}{\textbf{TODO}}
	\end{center}
	
\end{document}