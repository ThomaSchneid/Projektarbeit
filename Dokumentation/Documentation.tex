\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage{float}
\usepackage{color}
\usepackage[T1]{fontenc}
\usepackage{xcolor}
%\usepackage{listings}
\usepackage{pythonhighlight}


%New commands
\newcommand{\tief}{\textsubscript}
\newcommand{\hoch}{\textsuperscript}
\newcommand{\nl}{\newline}
\newcommand{\formelbox}[1]{\centerline{\fbox{#1}}}
\newcommand{\nin}{\noindent}
\newcommand{\nlparagraph}[1]{\paragraph{#1}\mbox{}\\}
\newcommand{\nlsubsubsection}[1]{\subsubsection{#1}\mbox{}\\}\newcommand{\nlformelbox}[1]{\centerline{\fbox{#1}}\mbox{}\\}

\begin{document}
	\title{Focus peaking - can edge detection improve the performance of current algorithms?}
	\author{Thomas Schneider \\ Matrikel-Nr: 60482 \\ Elektro- und Informationstechnik \\ Hochschule Karlsruhe}
	\onecolumn
	\maketitle
	\tableofcontents
	\twocolumn
	
	\section{Motivation/Einleitung}
	
	Wenn es um Bild- und Objekterkennung geht ist das menschliche Auge ungeschlagen. Innerhalb von wenigen Millisekunden erkennt es Kanten, klassifiziert Objekte, ist imstande diese zu benennen und erkennt den Unterschied zwischen einer Zeichnung, einem Bild und der Realität. Es gibt viele Algorithmen zur Kantenerkennung, jedoch ist keiner von ihnen so Leistungsstark und Effizient wie das menschliche Auge. Nicht nur ist der Canny Algorithmus der wohl bekannteste, sondern auch der am meist benutzte.\nl
	Der Canny-Algorithmus benutzt mehrere Stufen um in kurzer Zeit zu einem faszinierenden Ergebnis zu gelangen. Während ich meine Seminararbeit im Bereich der Kantenverfolgung geschrieben habe, kam ich nicht umhin auch erste Erfahrungen mit dem Canny-Algorithmus zu sammeln.
	Präzise und mit durchschnittlich \textcolor{red}{TODO ZEITWERT CANNY NACHSCHLAGE} x Sekunden für ein durchschnittliches, mit einer digitalkamera aufgenommenes Bild auch extrem schnell findet dieser Algorithmus alle Kanten des Bildes, markiert diese und gibt das so veränderte Bild zurück.\nl
	Neben all der Faszination stellte sich mir schnell die Frage, ob man den Algorithmus nicht durch Kantenverfolgung statt der reinen Kantenerkennung noch schneller machen könne. Mit dieser Frage beschäftige ich mich nachfolgend, werde einen Kantenverfolgungsalgorithmus entwickeln und evaluieren ob und zu was für einem eventuellen Preis man den Canny-Algorithmus so verschnellern kann.\nl
	Um den nachfolgenden Gedankengängen besser folgen zu können, schauen wir uns zuerst einmal vereinfacht an,  mit welchen Schritten der Canny-Algorithmus zum Ziel kommt. Die genannten Methoden werden im wieteren Verlauf dieses Dokuments mathematisch näher beleuchtet.\nl
	Der Canny Algorithmus lässt sich in 5 Schritte unterteilen:
	
	\begin{enumerate}
		\item Entfernen von Rauschen \textcolor{red}{Schöner FORMULIEREN}
		\item Suchen der Kanten im Bild
		\item Ausdünnen der gefunden Kanten
		\item Klassifizierung der Kantenpixel
		\item Vervollständigung der Kante
	\end{enumerate}
	
	Zuallererst wird vorhandenes Rauschen, welches unter anderem die Grauwerte der einzelnen Bildpixel verfälschen kann, im Bild entfernt. Dies ist ein Schritt, um welchen man auch bei Anwendung einer Kantenverfolgungsmethode nicht umhin kommt.\nl
	Anschließend wird für jedes Pixel ein Grauwert und der gradient berechnet. Dies geschieht für jedes einzelne Pixel des Bildes.\nl
	Die so gefundenen Kantenpixel wurden schon alle Kanten im Bild erkannt, allerdings sind diese noch sehr grob und unfein. Indem erneut alle Pixel des Bildes durchlaufen und die jeweiligen direkten Nachbarn in gradientenrichtung geprüft und die entsprechenden Grauwerte gegebenenfalls angepasst werden. So werden grobe, unfeine und breite Kanten ausgedünnt und feiner dargestellt.\nl
	Durch eine nochmalige Prüfung eines jeden Pixels werden die noch vorhandenen Kantenpixel klassifiziert und als starkes, schwaches oder kein Kantenpixel eingestuft, was das Kantenbild nochmal etwas verfeinert.\nl
	Abschließend werden eventuelle Lücken in Kanten durch ein Hystereseverfahren geschlossen, wofür ebenfalls alle Pixel des Bildes durchlaufen werden müssen.\nl
	Insgesamt durchlaufen wir das komplette Bild also mehrmals um einzelne Kantenpixel zu finden, diese zu klassifizieren und im Nachhinein die eventuell falsch klassifizierten oder gefundenen wieder zu korrigieren.\nl
	Genau hier greift meine Idee der involvierung einer Kantenverfolgung an. Wenn wir bereits im ersten Durchlauf ein Kantenpixel finden, können wir komplette Kante durch verfolgen der Kantenrichtung und Erkennung der anderen Pixel auf dem Weg erhalten. Dies würde die Anzahl der Zugriffe auf ein Pixel reduzieren und damit die Geschwindigkeit des Algorithmus erhöhen.\nl
	Gerade auf dem Gebiet des Auto-Focus und der Hochgeschwindigkeitsfotografie ist eine Geschwindigkeitssteigerung um bereits wenige Millisekunden ein enormer Gewinn.\nl
	
	Im Folgenden erläutere ich die einzelnen Methoden des Canny Algorithmus mathematisch genauer, werde meine Ansätze sowie meinen Algorithmus präsentieren und ihn direkt mit dem Canny Algorithmus vergleichen um zu sehen ob und welche Performancesteigerungen es gibt.
	
	\section{Begriffsdefinitioen und Erklärungen}

		\subsection{Was ist eine Kante}
			Eine Kante zeichnet sich dadurch aus, dass sich der Intensitätswert innerhalb weniger Pixel stark ändert.
			Hierbei muss allerdings nicht jeder Intensitätswertunterschied auch eine Kante sein, meist bewertet ein Algorithmus ob der Intensitätswertunterschied groß genug ist, als dass es sich um eine Kante handelt.
			
		\subsection{Pixelnachbarn}
			Unter Nachbarschaft versteht man in der Bildverarbeitung einen fest definierten Bereich um ein Pixel. Die zwei Grundkonzepte der Nachbarschaft sind die Vierer-Nachbarschaft (auch D-Nachbarschaft genannt) und die Achter-Nachbarschaft (\textit{Fig. 1}). 
			
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.6\linewidth] {../Dokumentation/Bilder/nachbarschaft}
				\caption{\textit{Vierer-Nachbarschaft (links) und Achter-Nachbarschaft (rechts)}}
			\end{figure}
			
			Wir benutzen im weiteren Verlauf stets die Achter-Nachbarschaft, da wir auch die diagonalen Nachbarn eines Pixels in die Kantenberechnung mit einbeziehen.
		
		\subsection{Bildrauschen}
			Bei Bildrauschen handelt es sich um zufällige Schwankungen, mit welchen die Informationen eines Pixels, beispielsweise Farbe oder Helligkeit, überlagert werden. Je mehr Pixel advon betroffen sind, desto höher ist das Rauschen im Bild.\nl 
			
			\nlsubsubsection{Wie entsteht Rauschen in digitalen Bildern}
				Bei Digitalkameras kann es aufgrund unterschiedlicher Ursachen zu Rauschen kommen.\nl
				
				\nlparagraph{Quantenrauschen}					
					Die riesige Lichtmenge, welche auf einen elektronischen Sensor fällt besteht aus vielen Elemtarteilchen, den sogenannten Photonen. Obwohl ein Lichtstrom für das menschliche Auge gleichmäßig aussieht, treffen die Photonen zufällig auf die einzelnen Pixel des Sensors. Wenn man eine große Sensorfläche über eine lange Zeit hinweg observiert wird man eine gleichmäßige Verteilung der Photonen feststellen. Observiert man hingegen einen kleinen Sensor für nur einen kurzen Zeitabschnitt wird man feststellen, dass die einzelnen Pixel des Sensors unterschiedlich viele Photonen empfangen haben. Nimmt man ein stark belichtetes, helles Bild auf, so treffen - da es viel Licht gibt - viele Photonen auf den Sensor. Dies führt dazu, dass man die zufällige Verteilung, das Rauschen, im fertigen Bild weniger stark wahrnimmt.\nl
					Bei dunklen Bildern hingegen treffen weniger Photonen auf den Sensor wodurch die zufällige Verteilung auf die Pixel extreme Abweichungen ergeben kann. Das Quantenrauschen ist bei dunkleren Bildern also stärker als bei hellen.\nl
					
				\nlparagraph{Beuteileigenschaften}
					Die auf dem Sensor angekommenen Photonen werden von einem Verstärker in Elektronen umgewandelt. Mit kleinen Kondensatoren wird die Ladung auf dem Chip gesammelt und in eine Spannung umgesetzt. Vor jeder neuen Bilderfassung müssen die Kondensatoren also "entleert" werden wobei es zur sogenannten \textit{Reset-Noise} kommt. Das entleeren geschieht mitnichten ideal oder gleichmäßig, wodurch es zu Restspannungen und damit einer zufälligen Schwankung um Ergebnis kommt. Diese Schwankung macht sich im Bild als Rauschen bemerkbar.\nl
					Weiterhin muss in vielen Schaltungen ein Ruhestrom fließen, welche zusätzlich für ein Rauschen im Bild sorgt.\nl
					
				\nlparagraph{Thermisches Rauschen}
					Eletrkonen bewegen sich bei erhöhter Temperatur mehr. So kann es bereits bei Raumtemperaturen zu Elektronenbewegungen und damit thermischem Rauschen kommen.\nl
					
				\nlparagraph{Quantisierungsrauschen}
					Um die analogen Spannungswerte in digitale Daten umzuwandeln wird ein Analog-Digital-Wandler angewendet. Die von einem AD-Wandler erzeugten Signalfehler sind allerdings nicht zufällig. Da bei unserem Fall bereits das Eingssignal zufälligkeiten Aufweist, sind auch diese Signalfehler nichtmehr zuverlässig vorhersagbar. Diese resultierende Schwankung in den Spannungswerten wird \textit{Quantisierungsrauschen} genannt. Die heutige Technik ist so weit entwickelt, dass Quantisierungsrauschen keinen Nennenswerten Beitrag zum Bildrauschen mehr leistet.\nl
			
			\nlsubsubsection{Methoden zur Rauschunterdrückung}
				Es gibt eine Vielzahl von Methoden um das Bildrauschen sowohl bereits vor der Entstehung des Bildes zu mindern als auch im Nachgang durch Bearbeitung des Bildes zu entfernen. In dieser Arbeit beschränken wir uns auf die Methode der örtlichen Faltung mit einer 3$\times$3 Filtermaske, genauer noch auf einen Gauß-Filter mit einer 3$\times$3 Kern.\nl
		
			\nlsubsubsection{Gauß Filter}
				Der Gauß Filter ist ein linearer Filter, welcher in der Bildverarbeitung zur Glättung des Bildes und Verminderung von Rauschen, vor allem weißem,  verwendet wird. Feinere Strukturen des Bildes gehen hierbei verloren, wobei gröbere erhalten bleiben.
				Ein Gaußscher Filterkern der Größe (2k + 1)$\times$(2k + 1) kann mit
				\medbreak
				\formelbox{H\tief{ij} = $\frac{1}{2\pi\sigma\hoch{2}}$ * $\mathrm{e}$\hoch{-$\frac{(i - (k + 1))\hoch{2} + (j - (k + 1))\hoch{2}}{2\sigma\hoch{2}}$}}
				\medbreak
				berechnet werden. \nl		
	
	\section{Canny-Algorithmus}
	
		\subsection{Gauß Kern}
			Für die Faltung benutzen wir einen oben bereits beschriebenen Gauß Kern. Als Programmiersprache benutzen wir Python und realisieren die Berechnung des Gauß Kerns folgendermaßen:
			
			\begin{python}
				def g_kern(mask, sigm=1.8):
				mask = int(mask) // 2
				x, y = np.mgrid[-mask:mask + 1,
				-mask:mask + 1]
				norm = 1 / (2 * np.pi * sigm ** 2)
				kern = np.exp(-((x ** 2 + y ** 2) / 
				(2 * sigm ** 2))) * norm
				
				return kern
			\end{python}
			
		\subsection{Sobel Operator}
			Der Sobel Operator besteht aus zwei 3$\times$3 Faltungskernen, wobei ein Kern dem jeweils anderen um 90° gedreht entspricht.
		
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.6\linewidth] {../Bilder/sobel_operator}
				\caption{\textit{Links der Faltungskern für die X- und rechts für die Y-Richtung.}}
			\end{figure}
	
			Für jedes Pixel werden die Komponenten der Matrix aufsummiert um den Grauwert zu erhalten.
		
			In Python realisieren wir den Sobel Filter folgendermaßen:
		
			\begin{python}
				def sobel(img):
					Gx = np.array([[-1, 0, 1], [-2, 0, 2],
					[-1, 0, 1]], np.float32)
					Gy = np.array([[1, 2, 1], [0, 0, 0],
					[-1, -2, -1]], np.float32)
			
					ablx = ndimage.filters.convolve(img, Gx)
					.astype(float)
					ably = ndimage.filters.convolve(img, Gy)
					.astype(float)
			
					res = np.hypot(ablx, ably)
					res = res / res.max() * 255
					gradient = np.arctan(ably, ablx)
			
					return res, gradient
			\end{python}
	
		\subsection{Non Maximum Suppression}
			Die Non Maximum Suppression Technik wird angewendet um bereits gefundene Intensitätsmaxima (Kanten) erneut zu prüfen und diese auszudünnen. Hierfür durchläuft der Algorithmus jedes gefundene Kantenpixel und vergleicht, basierend auf dem Gradienten des jeweiligen Pixels, die entsprechenden Nachbarpixel. Sollte eines der Nachbarpixel einen höheren Grauwert als das aktuelle Pixel aufweisen, wird der Grauwert des aktuellen Pixels auf 0 gesetzt.
	
			\begin{figure}[H]
				\centering
				\includegraphics[width=1\linewidth] {../Bilder/nms_how_to}
				\caption{\textit{Darstellung der Non Maximum Suppression Technik}}
			\end{figure}

			Schauen wir uns nun das untere, rot umrahmte Pixel etwas genauer an. Die Richtung der Kante wird hier durch den blauen Pfeil symbolisiert und entspricht einem Winkel von $\frac{\pi}{2}$ (90°).
	
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.7\linewidth] {../Bilder/nms_inspect_pixel}
				\caption{\textit{Nähere Betrachtung eines einzigen Pixels}}
			\end{figure}
	
			Die Richtung der Kante wird durch den grünen Pfeil dargestellt und verläuft vertikal von oben nach unten. Der Algorithmus prüft nun, ob die Pixel ober- und unterhalb (im Bild blau markiert) des ausgewählten Pixels (im Bild rot) einen höheren Intensitätswert aufweisen. In unserem Beispiel ist der Intensitätswert des unteren Pixels (i + 1, j) höher als der der anderen Beiden (das untere Pixel ist weiß und hat damit einen Intensitätswert von 255). Der Intensitätswert des aktuellen Pixels wird nun auf 0 gesetzt. Hätte keines der beiden anderen Pixel einen höheren Intensitätswert, würde der aktuelle Wert beibehalten werden.\nl
			Jedes Pixel hat also 2 Hauptkriterien, die Gradientenrichtung und den Intensitätswert. Die Non Maximum Suppression nutzt diese beiden Merkmale und führt folgende Schritte durch:
	
			\begin{itemize}
				\item Ein mit Nullen initialiiertes Abbild  der Gradientenmatrix erstellen.
				\item Kantenrichtung anhand der Gradientenmatrix erkennen.
				\item Prüfen ob Pixel entlang der Kantenrichtung einen höheren Intensitätswert als das aktuelle Pixel haben.
				\item Das mit dem Non Maximum Suppression Algorithmus bearbeitete Bild zurückgeben.
			\end{itemize}

			Den Non-Maximum-Suppression Algorithmus haben wir in Python folgendermaßen implementiert:
	
			\begin{python}
				def non_max_suppression(img, grad):
					y, x = img.shape
					blackscreen = np.zeros(img.shape)
					angle = grad * 180. / np.pi
					angle[angle < 0] += 180
					
					for i in range(1, y - 1):
						for j in range(1, x - 1):
							if img[i, j] != 0:
								try:
									q = 255
									r = 255
							
							# angle 0
							if (0 <= angle[i, j] < 22.5) or 
							(157.5 <= angle[i, j] <= 180):
								q = img[i, j + 1]
								r = img[i, j - 1]
							
							# angle 45
							elif 22.5 <= angle[i, j] < 67.5:
								q = img[i + 1, j - 1]
								r = img[i - 1, j + 1]
		
							# angle 90
							elif 67.5 <= angle[i, j] < 112.5:
								q = img[i + 1, j]
								r = img[i - 1, j]
		
							# angle 135
							elif 112.5 <= angle[i, j] < 157.5:
								q = img[i - 1, j - 1]
								r = img[i + 1, j + 1]
					
					if (img[i, j] >= q) and (img[i, j] >= r):
						blackscreen[i, j] = img[i, j]
					else:
						blackscreen[i, j] = 0
					
					except IndexError as e:
					pass
					
					return blackscreen
		\end{python}
	
		\subsection{Double threshold}
			Der double threshold Filter unterteilt unser Bild in 3 Arten von Pixeln
	
			\begin{enumerate}
				\item \textbf{Starke Pixel}
				\begin{itemize}
					\item Pixel, deren Intensitätswert hoch genug ist, dass wir uns sicher sein können, dass sie ein Teil der finalen Kante sind.
				\end{itemize}
				\item \textbf{Schwache Pixel}
				\begin{itemize}
					\item Pixel, deren Intensitätswert nicht hoch genug ist um als starkes Pixel eingestuft zu werden, allerdings hoch genug ist um nicht als unsignifikant für die Kantenerkennung zu sein.
				\end{itemize}
				\item \textbf{Andere Pixel}
				\begin{itemize}
					\item Alle Pixel, welche keine der anderen beiden Bedingungen erfüllen.\nl
				\end{itemize}
			\end{enumerate}

			Es wird eine Obergrenze (high threshold) und eine Untergrenze (low threshold) für die Intensitätswerte festgelegt. Ist der Intensitätswert eines Pixels höher als oder gleich der Obergrenze, wird es als starkes Pixel markiert, der Intensitätswert also auf 255 gesetzt. Befindet sich der Intensitätswert des Pixels zwischen Ober- und Untergrenze, wird es als schwaches Pixel markiert. Sollte der Intensitätswert des Pixels kleiner als oder gleich der Untergrenze sein, wird er auf 0 gesetzt. \nl
			Die beiden Schwellenwerte werden abhängig vom Eingangsbild berechnet, in unserem Beispiel durch den Faktor 0.05 für die untere und 0.09 für die obere Schwelle. In Python setzen wir die double threshold Funktion folgendermaßen um:
	
			\begin{python}
				def double_threshold(img,
				unterer_faktor=0.05, oberer_faktor=0.09):
					obere_schwelle = img.max() * oberer_faktor
					untere_schwelle = obere_schwelle *
												 unterer_faktor
					blackscreen = np.zeros(img.shape)
				
					starkes_pixel = 255
					schwaches_pixel = 25
					keine_kante = 0
					
					starkes_pixel_i, starkes_pixel_j =
					np.where(img >= obere_schwelle)
					
					keine_kante_i, keine_kante_j =
					np.where(img <= untere_schwelle)
					
					schwaches_pixel_i, schwaches_pixel_j =
					np.where((img < obere_schwelle) &
					(img > untere_schwelle))
					
					blackscreen[starkes_pixel_i,
					starkes_pixel_j] = starkes_pixel
					
					blackscreen[schwaches_pixel_i,
					schwaches_pixel_j] = schwaches_pixel
					
					blackscreen[keine_kante_i,
					keine_kante_j] =
					keine_kante
					
					return blackscreen
			\end{python}

		\subsection{Kantenvervollständigung durch Hysterese}
			\textbf{\textcolor{red}{TITEL ÄNDERN}}
			Durch eine Hysterese wird festgelegt, ab welcher Kantenstärke ein Pixel zu einer Kante gehört. Gemäß unserem obigen Codebeispiel setzen wir die obere Schwelle T\tief{2} auf 255 und die untere Schwelle T\tief{1} auf 25.
			 Anhand dieser zwei Schwellwerte (T\tief{1} < T\tief{2}) wird jedes Pixel des Bildes überprüft. Falls ein Pixel ein \textit{schwaches Pixel} ist, also einen Intensitätswert von 25 aufweist, werden all seine Nachbarn  geprüft. Sollte einer der Nachbarpixel ein starkes Pixel sein (oder, im allgemeinen, einen noch höheren Intensitätswert als T\tief{2} aufweisen), so wird auch das aktuell schwache Pixel als starkes Pixel markiert. Andernfalls wird der Intensitätswert des Pixels auf 0 gesetzt, da es nicht zur Kante gehört. Hierdurch werden alle kanten vervollständigt und alleinstehende, nur eventuell zu einer Kante gehörende, Pixel eliminiert. Die beschriebene Hysteresefunktion realisieren wir durch folgenden Python Code:
		
			\begin{python}
				def hysterese(img, schwaches_pixel,
				starkes_pixel=255):
					y, x = img.shape
					for i in range(1, y - 1):
						for j in range(1, x - 1):
							if img[i, j] == schwaches_pixel:
								try:
									if (
									(img[i + 1, j - 1] == 
									starkes_pixel)
									or 
									(img[i + 1, j] == starkes_pixel)
									or
									(img[i + 1, j + 1] ==
									starkes_pixel)
									or
									(img[i, j - 1] == starkes_pixel)
									or
									(img[i, j + 1] == starkes_pixel)
									or
									(img[i - 1, j - 1] ==
									starkes_pixel)
									or
									(img[i - 1, j] == starkes_pixel)
									or
									(img[i - 1, j + 1] ==
									starkes_pixel)):
										img[i, j] = starkes_pixel
									else:
										img[i, j] = 0
								except IndexError as e:
									pass
					
					return img
			\end{python}
		
	\section{Kantenerkennung mit dem Canny Algorithmus}
		Im folgenden werden die oben genannten Schritte des Canny Algorithmus einzeln auf ein Bild angewendet und näher erläutert.	
	
		\subsection{Noise Reduction}
			Kantenerkennung ist sehr anfällig für Rauschen, da die meisten und ausschlaggebendsten mathematischen Operationen auf Ableitungen basieren. Deshalb muss eventuell vorhandenes Rauschen im ersten Schritt entfernt werden.
			Hierfür wir beim Canny Algorithmus das Bild mithilfe eines Gauß Filters geglättet. Mit einem Gaußschen Kernel (hier 5x5) wird der Intensitätswert an der Stelle (i,j) durch das gewichtete Mittel der ihn umgebenden Werte ersetzt.
			Der resultierende "blurring" Effekt hängt unmittelbar mit der Wahl der Kerngröße zusammen - je größer der Kern,  desto besser ist auch der blurring Effekt. Mit steigender Kerngröße steigt jedoch auch die benötigte Rechenzeit, weshalb wir hier nur einen 5x5 Kern nehmen, welcher ein ausreichend gutes Ergebnis bei gleichzeitig guter Performance mit sich bringt.\nl
		
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.8\linewidth] {../Bilder/blur_result}
				\caption{\textit{Links das Original und rechts unter Anwendung der Noise reduction.}}
			\end{figure}
		
			Das verrauschte Bild wurde Kontrastreicher und Kanten dadurch deutlicher erkennbar.\nl
			Im Nachfolgenden werden wir unseren selbst gebauten Canny anhand des Hochshcullogos testen. Hier entfällt der erste Schritt, da das Hochschullogo ein digital erzeugtes Bild ist und somit kein Rauschen beinhaltet.\nl
			Hier das Originalbild des Hochschullogos in Graustufen:
			
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.5\linewidth]{../Bilder/hochschullogo}
				\caption{\textit{Schwarzweissbild des Hochschullogos.}}
			\end{figure}
			
		\subsection{Edge and Gradient Calculation}
			Nun wird berechnet, ob ein Pixel zu einer Kante gehört und gegbenenfalls die Richtung der Kante. Ob ein Pixel einer Kante zugehörig ist wird anhand der Intensiätsänderung bezüglich der Umliegenden Pixel bestimmt. Hierfür werden die Intensitätsänderungen in horizontaler sowie vertikaler Richtungeines jeden Pixels bezüglich seiner Nachbarn berechnet.\nl	
			Mathematisch realisiert wird dies durch eine Faltung des Bildes mit einem Sobel Kern. 
		
			Für die Intensität ergibt sich folgende Formel:\nl
		
			\nlformelbox{|G| = $\sqrt{I\tief{x}\hoch{2} + I\tief{y}\hoch{2}}$}
		
			Während der Gradient sich wie folgt berechnen lässt:\nl
		
			\nlformelbox{$\Theta$(x,y) = arctan($\frac{I\tief{y}}{I\tief{x}})$}
		
			Nach diesem Schritt hat man bereits ein Ergebnis, anhand welchem man die Kanten eines Bildes erkennen kann. Die gefundenen Kanten sind jedoch noch sehr grob und undetailiert.\nl
		
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.5\linewidth] {../Bilder/sobel_after_blur}
				\caption{\textit{Bild nach Anwendung des Sobel Filters}}
			\end{figure}
		
			Das Ergebnis muss also noch weiter verarbetet werden um Kanten auszudünnen, fehlerhaft als Kante erkannte Pixel zu entfernen und die Darstellung zu verfeinern. Hier setzen wir mit der Non-Maximum-Suppression an.\nl
		
		\subsection{Non Maximum Suppression}
			Die momentan noch mehr als 1 Pixel breiten Kanten werden nun mit dem Non-Maximum Suppression-Algorithmus ausgedünnt. Hierbei wird das gesamte Bild durchlaufen und jedes Pixel auf seinen Gradienten und Intensitätswert geprüft. Abhängig davon werden die Intensitätswerte der jeweiligen beiden Nchbarpixel mit dem Intensitätswert des aktuellen Pixels verglichen. Hat eines der beiden Nachbarpixel einen höheren Intensitätswert als das aktuelle Pixel, wird der Intensitätswert des aktuellen Pixels auf 0 gestezt. Sollte das aktuelle Pixel einen höheren Intensitätswert als die beiden Nachbarn aufweisen, so bleibt sein Intensitätswert unverändert. Nachdem der Algorithmus das Bild durchlaufen hat, ergibt sich ein neues Bild in welchem nur die Pixel entlang der gefundenen Kanten mit maximalen Intensitätswerten behalten wurden und alle anderen nun den Intensitätswert 0 aufweisen, also nichtmehr zur Kante gehören. Unser Hochschullogo sieht nun folgerndermaßen aus:
		
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.5\linewidth] {../Bilder/nms_after_sobel}
				\caption{\textit{Bild nach Anwendung der Non Maximum Suppression}}
			\end{figure}
		
			Verglichen mit dem Bild aus dem vorherigen Schritt kann man erkennen, dass die Kanten deutlich dünner und detailierter wurden. Man kann das Logo nun bereits gut nur anhand der Kanten erkennen. Die Intensitätswerte der nun gefundenen Kanten variieren jedoch noch stark. Viele Bildverarbeitungsprogramme oder auch Algorithmen basieren darauf, dass die gefundenen Kanten einen einzige Intensitätswert aufweisen und verarbeiten das Bild dann anhand des angegebenen Intensitätswertes. Um auch unseren Kanten einen eingeutlichen Intensitätswert zu geben nutzen wir die folgenden zwei Schritte.\nl
		
		\subsection{Double threshold}
			Der Double Threshold Filter arbeitet mit 2 Schwellenwerten, einem oberen und einem unteren. Die Intensitätswerte eines jeden Pixels werden geprüft und mit den Schwellenwerten verglichen. Je nachdem wo sich der Intensitätswert eines Pixels bezüglich der Schwellenwerte einordnen lässt, wird das Pixel in eine der folgenden Kateforien eingestuft und sein Intensitätswert dahingehend angepasst:\nl
			
			\begin{enumerate}
				\item starkes Pixel, Intensitätswert wird auf 255 gesetzt.
				\item schwaches Pixel, Intensitätswert wird (meist)  auf den unteren Schwellenwert gesetzt.
				\item nicht der Kante zugehörig, Intensitätswert wird auf 0 gesetzt.
			\end{enumerate}
			
			Nach Anwendung des Double Threshold Filters sieht unser Hochschullogo fogendermaßen aus:\nl
			
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.5\linewidth] {../Bilder/double_threshold_after_nms}
				\caption{\textit{Bild mit starken (weiss) und schwachen (grau) Pixeln}}
			\end{figure}
	
			Die starken Kanten sind heller und klarer erkennbar. Ebenso sind leichte, nach der Non Maximum Suppression noch vohandene unfeinheiten oder einzelne Kantenpixel beseitigt worden.\nl
	
		\subsection{Hysteresis}
			Im letzten Schritt wenden wir noch eine Hysterese auf das gesamte Bild an, um die einzelnen Pixel noch einmal final zu überprüfen und eventuelle Lücken in Kanten zu schließen oder alleinstehende und damit fälschlicherweise erkannte Kantenpixel zu eliminieren.\nl 
			Jedes Pixel wird auf seine 8 direkten Nachbarn geprüft.\nl
			Befindet sich in der direkten Nachbarschaft eines Pixels kein starkes Pixel, so wird der Intensitätswert des Pixels auf 0 gesetzt und es ist damit kein Kantenpixel mehr.\nl
	
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.8\linewidth] {../Bilder/no_strong_pixel_around}
				\caption{\textit{Ein Pixel ohne starkes Pixel in der Nachbarschaft}}
			\end{figure}
	
			Befindet sich unter den direkten Nachbarn des Pixels ein starkes Pixel, so wird der Intensitätswert des aktuellen Pixels auf 255 gesetzt, es wird ebenfalls zu einem starken Pixel.\nl
	
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.8\linewidth] {../Bilder/one_strong_pixel_around}
				\caption{\textit{Ein Pixel mit einem starken Pixel in der Nachbarschaft}}
			\end{figure}
	
			Nach all diesen Schritten ist dies unser finales Kantenbild:\nl
		
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.5\linewidth] {../Bilder/hysteresis_after_threshold}
				\caption{\textit{Finales Bild}}
			\end{figure}
	
			Es ist frei von alleinstehenden Kantenpixeln und die gefundenen Kanten sind fein und deutlich zu erkennen.\nl
			
		\subsection{Vergeich}
			Nun wollen wir den eigens Entwickelten Canny Algorithmus mit dem wirklichen Canny Algorithmus vergleichen. Hier das Kantenbild des richtigen Canny Algorithmus und unseres als Vergleich:\nl
			
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.9\linewidth] {../Bilder/our_canny_vs_real_one}
				\caption{\textit{Kantedektion mit unserem Algorithmus (links) und mit dem richtigen Canny (rechts)}}
			\end{figure}
			
			Man erkennt den Unterschied sofort, der richtige Canny Algorithmus hat die Kanten noch mehr ausgedünnt und verfeinert. Im Vergleich dazu sind unsere Kanten noch immer sehr dick und unfein.\nl
			Werfen wir nun einen Blick auf die Rechenzeit:\nl
			Während unser Algorithmus mit 1.221 Sekunden für das Hochschullogo nicht langsam ist, setzt Canny mit 0.026 Sekunden, der knapp 48-fachen Geschwindigkeit, für die Kantenerkennung des Hochschullogos Maßstäbe in ganz anderen Dimensionen. Mit einer einfachen Nachbildung des Canny Algorithmus ist es also nicht getan.\nl
	
	\section{Effizienzgewinn durch Kantenverfolgung}
		\subsection{Idee}
			Es ist nicht notwendig, das komplette Bild und damit jedes einzelne Pixel mehrmals zu überprüfen und berechnen.\nl
			Sobald beim Durchlaufen des Bildes ein Kantenpixel gefunden und die Kantenrichtung bestimmt wurde, kann man mit einem Kantenverfolgungsalgorithmus dieser Kante bis zum Ende folgen und auf dem Weg jedes Pixel der Kante entsprechend berechnen und markieren.\nl
			Beginnt man bei dieser Variante allerdings gleich wie beim Canny Algorithmus, das Bild Pixel für Pixel zu untersuchen, müsste man auch hier, sobald ein Kantenpixel gefunden und die Kante verfolgt wurde, das auf das Kantenpixel folgende Pixel prüfen, um sicherzustellen, dass man jede Kante im Bild gefunden hat.\nl
			Um also dem Grundgedanken, weniger Pixel zu prüfen und dadurch Rechenzeit einzusparen, nachzukommen, bedarf es einer Methode das Bild abzulaufen, welche von vornherein nicht jedes Pixel untersuchen würde, mithilfe der Kantenverfolgung jedoch trotzdem jedes Kantenpixel findet.\nl
			Als Referenzbild verwenden wir das folgende:\nl
		
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.5\linewidth] {../Bilder/camera_obscura}
				\caption{\textit{Testbild für unseren Kantenverfolgungsalgorithmus}}
			\end{figure}
		
			Dieses Bild enthält Kanten welche nahe beieinander liegen, größere, Grauwertemäßig nicht merklich unterschiedliche,  Flächen, weiter auseinanderliegende Kanten und Kanten unterschiedlicher breite, bis hin zu Linien. Es enthält zudem sowohl runde, als auch eckige oder kurvige Objekte. In diesem Bild sind die meisten Kantenformen enthalten, was es zu einem hervorragenden Testbild für unseren Algorithmus macht.\nl
			
		\subsection{Das Bild durchlaufen}
			Um sicherzustellen, dass von Beginn an nicht jedes Pixel des Bildes durchlaufen wird, wenden wir eine spezielle Suchmethode an.\nl
			
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.45\linewidth] {../Bilder/image_skeleton}
				\caption{\textit{Pixelskelett eines Bildes mit untersuchten Pixeln}}
			\end{figure}
		
			Wir durchlaufen das Bild von Links nach Rechts und untersuchen es dabei in horizontalen Linien, welche untereinander sowie vom oberen und den seitlichen Rändern einen Abstand von 3 Pixeln und vom unteren Rand einen Abstand von mindestens 3 Pixeln, maximal jedoch 5 Pixeln, haben.\nl
			Grund für diesen Abstand sind unsere Suchmasken. Wir untersuchen immer ein 3$\times$3 Quadrat der jeweils gegenüberliegenden Nachbarn. Für jedes so untersuchte Pixel berechnen wir also für 4 Richtungen, ob es sich um eine Kante handelt. Hier unsere 4 Suchmasken, der blaue Pfeil gibt jeweils die Kantenrichtung an:\nl
			
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.7\linewidth] {../Bilder/mask_2_mediane}
				\caption{\textit{Maske zur Untersuchung auf eine Kante in Richtung der 1. Mediane}}
			\end{figure}
	
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.7\linewidth] {../Bilder/mask_1_mediane}
				\caption{\textit{Maske zur Untersuchung auf eine Kante in Richtung der 2. Mediane}}
			\end{figure}
		
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.6\linewidth] {../Bilder/mask_horizontal}
				\caption{\textit{Maske zur Untersuchung auf eine Kante in horizontaler Richtung}}
			\end{figure}
	
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.7\linewidth] {../Bilder/mask_vertical}
				\caption{\textit{Maske zur Untersuchung auf eine Kante in vertikaler Richtung}}
			\end{figure}	

			Mit dieser Methode das Bild zu durchlaufen gibt es allerdings einige Kanten, welche wir nicht finden können. Sollte eine Kante zwischen 2 roten Suchlinien in horizontaler Richtung verlaufen und unverzweigt sein oder befindet sich eine Kante in weniger als 3 Pixeln Abstand, unverzweigt und parallel zum jeweiligen Rand, so können wir diese nicht finden.\nl
			Wir wollen unseren Algorithmus auf mit Digitalkameras aufgenommene Bilder anwenden, dass eine solche Kante im Bild vorkommt, sollte also verschwindend gering sein. Objekte in der Realität sind größer als 3 Pixel. Die Kanten eines Objekts sind verzweigt und schneiden somit unweigerlich eine der roten Linien. Wir können daher sicher sein, dass wir immer mindestens alle Objekte anschneiden und somit die Kante durch Kantenverfolgung auch zwischen horizontal zwischen 2 Linien verlaufend finden werden.\nl
			Die Höhe des Bildes in Pixeln sei y, die Breite x. Somit berechnet sich die Anzahl der durchlaufenen Pixel, ohne eine Kante zu verfolgen, auf:\nl
			
			\nlformelbox{Pixel\tief{ges} = $\frac{(y - 3)}{4}$ * (x - 6)}
			
			Im Verhältnis zu allen Pixeln des Bildes, prüfen wir somit mindestens\nl
			
			\nlformelbox{{$\frac{x * y - 3 * x - 6 * y + 18}{4 * x * y}$}}
			
			Was, da der Nenner hier schneller steigt als der Zähler, bei steigender Bildgröße ein immer kleinerer Anteil wird.\nl

			\begin{python}

			\end{python}
		
			Die Richtung (der Gradient) wurde dabei nach folgendem Algorithmus berechnet:
		
			\begin{python}
			
			\end{python}
	
			Ebenso war der Code zur Bestimmung des nächsten Pixels auf eine sehr triviale Weise vorhanden:
	
			\begin{python}
		
			\end{python}
	
			Hierbei traf ich auf das Problem, dass die Einsparung der Laufzeit durch direktes bearbeiten der Kantennachbarn sehr schnell wieder verloren geht und zwar dadurch, dass man mehrere Matrizen der Größe des Bildes benötigt um die einzelnen Stati wie neuer Grauwert, Richtung und ein \textit{bereits bearbeitet} Flag zu speichern. Diese muss man immer wieder abrufen, also die Matrizen laden, bearbeiten und verändert wieder abspeichern. Gerade bei größeren Bildern oder wenn eine Kante nicht mit dem Durchlaufen der Diagonalen gefunden wird, übersteigt die Laufzeit des geplanten Algorithmus die des Canny Algorithmus schnell.\nl
			Ebenso ist mit dem beschriebenen Vorgehen nicht sichergestellt, dass man alle Kanten findet. Um auch Objekte zum Beispiel am Rand zu finden müsste man das komplette Bild erneut mit einem Hysterese Algorithmus bearbeiten. \nl
			Trotz anfänglicher, guter Fortschritte hatte der geplante Algorithmus deshalb leider keine Aussicht auf Erfolg und eine Effizienzsteigerung des Canny Algorithmus durch Kantenverfolgung ist mit dieser Methode nicht möglich.
	
	\section{Literaturverzeichnis}
		\begin{itemize}
			\item \textit{http://www9.in.tum.de/seminare/hs.SS06.EAMA/material/\\01\_ausarbeitung.pdf}
			\item \textit{https://www.kuppelwieser.net/index.php/technik/15-bildverarbeitung/40-canny-algorithmus}
			\item \textit{http://mi.informatik.uni-siegen.de/teaching/lectures/EI/\\script/10eiComplexity.pdf}
			\item \textit{https://edoc.sub.uni-hamburg.de/haw/volltexte/2016/3266/pdf/\\BA\_Tamou.pdf}
			\item \textit{https://en.wikipedia.org/wiki/Canny\_edge\_detector}
		\end{itemize}
\end{document}