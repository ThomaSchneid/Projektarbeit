\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage{float}
\usepackage{color}
\usepackage[T1]{fontenc}
\usepackage{xcolor}
%\usepackage{listings}
\usepackage{pythonhighlight}


%New commands
\newcommand{\tief}{\textsubscript}
\newcommand{\hoch}{\textsuperscript}
\newcommand{\nl}{\newline}
\newcommand{\formelbox}[1]{\centerline{\fbox{#1}}}
\newcommand{\nin}{\noindent}
\newcommand{\nlparagraph}[1]{\paragraph{#1}\mbox{}\\}
\newcommand{\nlsubsubsection}[1]{\subsubsection{#1}\mbox{}\\}

\begin{document}
	\title{Focus peaking - can edge detection improve the performance of current algorithms?}
	\author{Thomas Schneider \\ Matrikel-Nr: 60482 \\ Elektro- und Informationstechnik \\ Hochschule Karlsruhe}
	\onecolumn
	\maketitle
	\tableofcontents
	\twocolumn
	
	\section{Motivation/Einleitung}
	
	Wenn es um Bild- und Objekterkennung geht ist das menschliche Auge ungeschlagen. Innerhalb von wenigen Millisekunden erkennt es Kanten, klassifiziert Objekte, ist imstande diese zu benennen und erkennt den Unterschied zwischen einer Zeichnung, einem Bild und der Realität. Es gibt viele Algorithmen zur Kantenerkennung, jedoch ist keiner von ihnen so Leistungsstark und Effizient wie das menschliche Auge. Nicht nur ist der Canny Algorithmus der wohl bekannteste, sondern auch der am meist benutzte.\nl
	Der Canny-Algorithmus benutzt mehrere Stufen um in kurzer Zeit zu einem faszinierenden Ergebnis zu gelangen. Während ich meine Seminararbeit im Bereich der Kantenverfolgung geschrieben habe, kam ich nicht umhin auch erste Erfahrungen mit dem Canny-Algorithmus zu sammeln.
	Präzise und mit durchschnittlich \textcolor{red}{TODO ZEITWERT CANNY NACHSCHLAGE} x Sekunden für ein durchschnittliches, mit einer digitalkamera aufgenommenes Bild auch extrem schnell findet dieser Algorithmus alle Kanten des Bildes, markiert diese und gibt das so veränderte Bild zurück.\nl
	Neben all der Faszination stellte sich mir schnell die Frage, ob man den Algorithmus nicht durch Kantenverfolgung statt der reinen Kantenerkennung noch schneller machen könne. Mit dieser Frage beschäftige ich mich nachfolgend, werde einen Kantenverfolgungsalgorithmus entwickeln und evaluieren ob und zu was für einem eventuellen Preis man den Canny-Algorithmus so verschnellern kann.\nl
	Um den nachfolgenden Gedankengängen besser folgen zu können, schauen wir uns zuerst einmal vereinfacht an,  mit welchen Schritten der Canny-Algorithmus zum Ziel kommt. Die genannten Methoden werden im wieteren Verlauf dieses Dokuments mathematisch näher beleuchtet.\nl
	Der Canny Algorithmus lässt sich in 5 Schritte unterteilen:
	
	\begin{enumerate}
		\item Entfernen von Rauschen \textcolor{red}{Schöner FORMULIEREN}
		\item Suchen der Kanten im Bild
		\item Ausdünnen der gefunden Kanten
		\item Klassifizierung der Kantenpixel
		\item Vervollständigung der Kante
	\end{enumerate}
	
	Zuallererst wird vorhandenes Rauschen, welches unter anderem die Grauwerte der einzelnen Bildpixel verfälschen kann, im Bild entfernt. Dies ist ein Schritt, um welchen man auch bei Anwendung einer Kantenverfolgungsmethode nicht umhin kommt.\nl
	Anschließend wird für jedes Pixel ein Grauwert und der gradient berechnet. Dies geschieht für jedes einzelne Pixel des Bildes.\nl
	Die so gefundenen Kantenpixel wurden schon alle Kanten im Bild erkannt, allerdings sind diese noch sehr grob und unfein. Indem erneut alle Pixel des Bildes durchlaufen und die jeweiligen direkten Nachbarn in gradientenrichtung geprüft und die entsprechenden Grauwerte gegebenenfalls angepasst werden. So werden grobe, unfeine und breite Kanten ausgedünnt und feiner dargestellt.\nl
	Durch eine nochmalige Prüfung eines jeden Pixels werden die noch vorhandenen Kantenpixel klassifiziert und als starkes, schwaches oder kein Kantenpixel eingestuft, was das Kantenbild nochmal etwas verfeinert.\nl
	Abschließend werden eventuelle Lücken in Kanten durch ein Hystereseverfahren geschlossen, wofür ebenfalls alle Pixel des Bildes durchlaufen werden müssen.\nl
	Insgesamt durchlaufen wir das komplette Bild also mehrmals um einzelne Kantenpixel zu finden, diese zu klassifizieren und im Nachhinein die eventuell falsch klassifizierten oder gefundenen wieder zu korrigieren.\nl
	Genau hier greift meine Idee der involvierung einer Kantenverfolgung an. Wenn wir bereits im ersten Durchlauf ein Kantenpixel finden, können wir komplette Kante durch verfolgen der Kantenrichtung und Erkennung der anderen Pixel auf dem Weg erhalten. Dies würde die Anzahl der Zugriffe auf ein Pixel reduzieren und damit die Geschwindigkeit des Algorithmus erhöhen.\nl
	Gerade auf dem Gebiet des Auto-Focus und der Hochgeschwindigkeitsfotografie ist eine Geschwindigkeitssteigerung um bereits wenige Millisekunden ein enormer Gewinn.\nl
	
	Im Folgenden erläutere ich die einzelnen Methoden des Canny Algorithmus mathematisch genauer, werde meine Ansätze sowie meinen Algorithmus präsentieren und ihn direkt mit dem Canny Algorithmus vergleichen um zu sehen ob und welche Performancesteigerungen es gibt.
	
	\section{Begriffsdefinitioen und Erklärungen}

		\subsection{Was ist eine Kante}
			Eine Kante zeichnet sich dadurch aus, dass sich der Intensitätswert innerhalb weniger Pixel stark ändert.
			Hierbei muss allerdings nicht jeder Intensitätswertunterschied auch eine Kante sein, meist bewertet ein Algorithmus ob der Intensitätswertunterschied groß genug ist, als dass es sich um eine Kante handelt.
			
		\subsection{Pixelnachbarn}
			Unter Nachbarschaft versteht man in der Bildverarbeitung einen fest definierten Bereich um ein Pixel. Die zwei Grundkonzepte der Nachbarschaft sind die Vierer-Nachbarschaft (auch D-Nachbarschaft genannt) und die Achter-Nachbarschaft (\textit{Fig. 1}). 
			
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.6\linewidth] {../Dokumentation/Bilder/nachbarschaft}
				\caption{\textit{Vierer-Nachbarschaft (links) und Achter-Nachbarschaft (rechts)}}
			\end{figure}
			
			Wir benutzen im weiteren Verlauf stets die Achter-Nachbarschaft, da wir auch die diagonalen Nachbarn eines Pixels in die Kantenberechnung mit einbeziehen.
		
		\subsection{Bildrauschen}
			Bei Bildrauschen handelt es sich um zufällige Schwankungen, mit welchen die Informationen eines Pixels, beispielsweise Farbe oder Helligkeit, überlagert werden. Je mehr Pixel advon betroffen sind, desto höher ist das Rauschen im Bild.\nl 
			
			\nlsubsubsection{Wie entsteht Rauschen in digitalen Bildern}
				Bei Digitalkameras kann es aufgrund unterschiedlicher Ursachen zu Rauschen kommen.\nl
				
				\nlparagraph{Quantenrauschen}					
					Die riesige Lichtmenge, welche auf einen elektronischen Sensor fällt besteht aus vielen Elemtarteilchen, den sogenannten Photonen. Obwohl ein Lichtstrom für das menschliche Auge gleichmäßig aussieht, treffen die Photonen zufällig auf die einzelnen Pixel des Sensors. Wenn man eine große Sensorfläche über eine lange Zeit hinweg observiert wird man eine gleichmäßige Verteilung der Photonen feststellen. Observiert man hingegen einen kleinen Sensor für nur einen kurzen Zeitabschnitt wird man feststellen, dass die einzelnen Pixel des Sensors unterschiedlich viele Photonen empfangen haben. Nimmt man ein stark belichtetes, helles Bild auf, so treffen - da es viel Licht gibt - viele Photonen auf den Sensor. Dies führt dazu, dass man die zufällige Verteilung, das Rauschen, im fertigen Bild weniger stark wahrnimmt.\nl
					Bei dunklen Bildern hingegen treffen weniger Photonen auf den Sensor wodurch die zufällige Verteilung auf die Pixel extreme Abweichungen ergeben kann. Das Quantenrauschen ist bei dunkleren Bildern also stärker als bei hellen.\nl
					
				\nlparagraph{Beuteileigenschaften}
					Die auf dem Sensor angekommenen Photonen werden von einem Verstärker in Elektronen umgewandelt. Mit kleinen Kondensatoren wird die Ladung auf dem Chip gesammelt und in eine Spannung umgesetzt. Vor jeder neuen Bilderfassung müssen die Kondensatoren also "entleert" werden wobei es zur sogenannten \textit{Reset-Noise} kommt. Das entleeren geschieht mitnichten ideal oder gleichmäßig, wodurch es zu Restspannungen und damit einer zufälligen Schwankung um Ergebnis kommt. Diese Schwankung macht sich im Bild als Rauschen bemerkbar.\nl
					Weiterhin muss in vielen Schaltungen ein Ruhestrom fließen, welche zusätzlich für ein Rauschen im Bild sorgt.\nl
					
				\nlparagraph{Thermisches Rauschen}
					Eletrkonen bewegen sich bei erhöhter Temperatur mehr. So kann es bereits bei Raumtemperaturen zu Elektronenbewegungen und damit thermischem Rauschen kommen.\nl
					
				\nlparagraph{Quantisierungsrauschen}
					Um die analogen Spannungswerte in digitale Daten umzuwandeln wird ein Analog-Digital-Wandler angewendet. Die von einem AD-Wandler erzeugten Signalfehler sind allerdings nicht zufällig. Da bei unserem Fall bereits das Eingssignal zufälligkeiten Aufweist, sind auch diese Signalfehler nichtmehr zuverlässig vorhersagbar. Diese resultierende Schwankung in den Spannungswerten wird \textit{Quantisierungsrauschen} genannt. Die heutige Technik ist so weit entwickelt, dass Quantisierungsrauschen keinen Nennenswerten Beitrag zum Bildrauschen mehr leistet.\nl
			
			\nlsubsubsection{Methoden zur Rauschunterdrückung}
				Es gibt eine Vielzahl von Methoden um das Bildrauschen sowohl bereits vor der Entstehung des Bildes zu mindern als auch im Nachgang durch Bearbeitung des Bildes zu entfernen. In dieser Arbeit beschränken wir uns auf die Methode der örtlichen Faltung mit einer 3$\times$3 Filtermaske, genauer noch auf einen Gauß-Filter mit einer 3$\times$3 Kern.\nl
		
			\nlsubsubsection{Gauß Filter}
				Der Gauß Filter ist ein linearer Filter, welcher in der Bildverarbeitung zur Glättung des Bildes und Verminderung von Rauschen, vor allem weißem,  verwendet wird. Feinere Strukturen des Bildes gehen hierbei verloren, wobei gröbere erhalten bleiben.
				Ein Gaußscher Filterkern der Größe (2k + 1)$\times$(2k + 1) kann mit
				\medbreak
				\formelbox{H\tief{ij} = $\frac{1}{2\pi\sigma\hoch{2}}$ * $\mathrm{e}$\hoch{-$\frac{(i - (k + 1))\hoch{2} + (j - (k + 1))\hoch{2}}{2\sigma\hoch{2}}$}}
				\medbreak
				berechnet werden. \nl		
	
	\section{Canny-Algorithmus}
	
		\subsection{Gauß Kern}
			Für die Faltung benutzen wir einen oben bereits beschriebenen Gauß Kern. Als Programmiersprache benutzen wir Python und realisieren die Berechnung des Gauß Kerns folgendermaßen:
			
			\begin{python}
				def g_kern(mask, sigm=1.8):
				mask = int(mask) // 2
				x, y = np.mgrid[-mask:mask + 1,
				-mask:mask + 1]
				norm = 1 / (2 * np.pi * sigm ** 2)
				kern = np.exp(-((x ** 2 + y ** 2) / 
				(2 * sigm ** 2))) * norm
				
				return kern
			\end{python}
			
		\subsection{Sobel Operator}
			Der Sobel Operator besteht aus zwei 3$\times$3 Faltungskernen, wobei ein Kern dem jeweils anderen um 90° gedreht entspricht.
		
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.6\linewidth] {../Bilder/sobel_operator}
				\caption{\textit{Links der Faltungskern für die X- und rechts für die Y-Richtung.}}
			\end{figure}
	
			Für jedes Pixel werden die Komponenten der Matrix aufsummiert um den Grauwert zu erhalten.
		
			In Python realisieren wir den Sobel Filter folgendermaßen:
		
			\begin{python}
				def sobel(img):
					Gx = np.array([[-1, 0, 1], [-2, 0, 2],
					[-1, 0, 1]], np.float32)
					Gy = np.array([[1, 2, 1], [0, 0, 0],
					[-1, -2, -1]], np.float32)
			
					ablx = ndimage.filters.convolve(img, Gx)
					.astype(float)
					ably = ndimage.filters.convolve(img, Gy)
					.astype(float)
			
					res = np.hypot(ablx, ably)
					res = res / res.max() * 255
					gradient = np.arctan(ably, ablx)
			
					return res, gradient
			\end{python}
	
		\subsection{Non Maximum Suppression}
			Die Non Maximum Suppression Technik wird angewendet um bereits gefundene Intensitätsmaxima (Kanten) erneut zu prüfen und diese auszudünnen. Hierfür durchläuft der Algorithmus jedes gefundene Kantenpixel und vergleicht, basierend auf dem Gradienten des jeweiligen Pixels, die entsprechenden Nachbarpixel. Sollte eines der Nachbarpixel einen höheren Grauwert als das aktuelle Pixel aufweisen, wird der Grauwert des aktuellen Pixels auf 0 gesetzt.
	
			\begin{figure}[H]
				\centering
				\includegraphics[width=1\linewidth] {../Bilder/nms_how_to}
				\caption{\textit{Darstellung der Non Maximum Suppression Technik}}
			\end{figure}

			Schauen wir uns nun das untere, rot umrahmte Pixel etwas genauer an. Die Richtung der Kante wird hier durch den blauen Pfeil symbolisiert und entspricht einem Winkel von $\frac{\pi}{2}$ (90°).
	
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.7\linewidth] {../Bilder/nms_inspect_pixel}
				\caption{\textit{Nähere Betrachtung eines einzigen Pixels}}
			\end{figure}
	
			Die Richtung der Kante wird durch den grünen Pfeil dargestellt und verläuft vertikal von oben nach unten. Der Algorithmus prüft nun, ob die Pixel ober- und unterhalb (im Bild blau markiert) des ausgewählten Pixels (im Bild rot) einen höheren Intensitätswert aufweisen. In unserem Beispiel ist der Intensitätswert des unteren Pixels (i + 1, j) höher als der der anderen Beiden (das untere Pixel ist weiß und hat damit einen Intensitätswert von 255). Der Intensitätswert des aktuellen Pixels wird nun auf 0 gesetzt. Hätte keines der beiden anderen Pixel einen höheren Intensitätswert, würde der aktuelle Wert beibehalten werden.\nl
			Jedes Pixel hat also 2 Hauptkriterien, die Gradientenrichtung und den Intensitätswert. Die Non Maximum Suppression nutzt diese beiden Merkmale und führt folgende Schritte durch:
	
			\begin{itemize}
				\item Ein mit Nullen initialiiertes Abbild  der Gradientenmatrix erstellen.
				\item Kantenrichtung anhand der Gradientenmatrix erkennen.
				\item Prüfen ob Pixel entlang der Kantenrichtung einen höheren Intensitätswert als das aktuelle Pixel haben.
				\item Das mit dem Non Maximum Suppression Algorithmus bearbeitete Bild zurückgeben.
			\end{itemize}

			Den Non-Maximum-Suppression Algorithmus haben wir in Python folgendermaßen implementiert:
	
			\begin{python}
				def non_max_suppression(img, grad):
					y, x = img.shape
					blackscreen = np.zeros(img.shape)
					angle = grad * 180. / np.pi
					angle[angle < 0] += 180
					
					for i in range(1, y - 1):
						for j in range(1, x - 1):
							if img[i, j] != 0:
								try:
									q = 255
									r = 255
							
							# angle 0
							if (0 <= angle[i, j] < 22.5) or 
							(157.5 <= angle[i, j] <= 180):
								q = img[i, j + 1]
								r = img[i, j - 1]
							
							# angle 45
							elif 22.5 <= angle[i, j] < 67.5:
								q = img[i + 1, j - 1]
								r = img[i - 1, j + 1]
		
							# angle 90
							elif 67.5 <= angle[i, j] < 112.5:
								q = img[i + 1, j]
								r = img[i - 1, j]
		
							# angle 135
							elif 112.5 <= angle[i, j] < 157.5:
								q = img[i - 1, j - 1]
								r = img[i + 1, j + 1]
					
					if (img[i, j] >= q) and (img[i, j] >= r):
						blackscreen[i, j] = img[i, j]
					else:
						blackscreen[i, j] = 0
					
					except IndexError as e:
					pass
					
					return blackscreen
		\end{python}
	
		\subsection{Double threshold}
			Der double threshold Filter unterteilt unser Bild in 3 Arten von Pixeln
	
			\begin{enumerate}
				\item \textbf{Starke Pixel}
				\begin{itemize}
					\item Pixel, deren Intensitätswert hoch genug ist, dass wir uns sicher sein können, dass sie ein Teil der finalen Kante sind.
				\end{itemize}
				\item \textbf{Schwache Pixel}
				\begin{itemize}
					\item Pixel, deren Intensitätswert nicht hoch genug ist um als starkes Pixel eingestuft zu werden, allerdings hoch genug ist um nicht als unsignifikant für die Kantenerkennung zu sein.
				\end{itemize}
				\item \textbf{Andere Pixel}
				\begin{itemize}
					\item Alle Pixel, welche keine der anderen beiden Bedingungen erfüllen.\nl
				\end{itemize}
			\end{enumerate}

			Es wird eine Obergrenze (high threshold) und eine Untergrenze (low threshold) für die Intensitätswerte festgelegt. Ist der Intensitätswert eines Pixels höher als oder gleich der Obergrenze, wird es als starkes Pixel markiert, der Intensitätswert also auf 255 gesetzt. Befindet sich der Intensitätswert des Pixels zwischen Ober- und Untergrenze, wird es als schwaches Pixel markiert. Sollte der Intensitätswert des Pixels kleiner als oder gleich der Untergrenze sein, wird er auf 0 gesetzt. \nl
			Die beiden Schwellenwerte werden abhängig vom Eingangsbild berechnet, in unserem Beispiel durch den Faktor 0.05 für die untere und 0.09 für die obere Schwelle. In Python setzen wir die double threshold Funktion folgendermaßen um:
	
			\begin{python}
				def double_threshold(img,
				unterer_faktor=0.05, oberer_faktor=0.09):
					obere_schwelle = img.max() * oberer_faktor
					untere_schwelle = obere_schwelle *
												 unterer_faktor
					blackscreen = np.zeros(img.shape)
				
					starkes_pixel = 255
					schwaches_pixel = 25
					keine_kante = 0
					
					starkes_pixel_i, starkes_pixel_j =
					np.where(img >= obere_schwelle)
					
					keine_kante_i, keine_kante_j =
					np.where(img <= untere_schwelle)
					
					schwaches_pixel_i, schwaches_pixel_j =
					np.where((img < obere_schwelle) &
					(img > untere_schwelle))
					
					blackscreen[starkes_pixel_i,
					starkes_pixel_j] = starkes_pixel
					
					blackscreen[schwaches_pixel_i,
					schwaches_pixel_j] = schwaches_pixel
					
					blackscreen[keine_kante_i,
					keine_kante_j] =
					keine_kante
					
					return blackscreen
			\end{python}

		\subsection{Kantenverfolgung durch Hysterese}
		
		Durch eine Hysterese wird festgelegt, ab welcher Kantenstärke ein Pixel zu einer Kante gehört. Mithilfe zweier Schwellwerte T\tief{1} < T\tief{2} wird jedes Pixel eines Bildes überprüft. Sobald ein Pixel einen Intensitätswert über T\tief{2} hat, wird diesem Pixel gefolgt und jedes Pixel entlang der so gefundenen Kante, dessen Intensitätswert größer T\tief{1} ist, als Element dieser Kante markiert.
		
		\pagebreak
		
		Wir realisieren unsere Hysterese Funktion in Python folgendermaßen:
		
		\begin{python}
			def hysteresis(img, weak, strong=255):
 				M, N = img.shape    # c10 * 1
				for i in range(1, M - 1):   # c14 * (M - 2)
					for j in range(1, N - 1):   
					# c15 * ((M - 2) * (N - 2))
						if img[i, j] == weak:   
						# c31 * ((M - 2) * (N - 2))
							try:    
							# c16 * (((M - 2) * (N - 2)) - Z)
								if ((img[i + 1, j - 1] == strong) or 
								(img[i + 1, j] == strong) or 
								(img[i + 1, j + 1] == strong) or 
								(img[i, j - 1] == strong) or 
								(img[i, j + 1] == strong) or 
								(img[i - 1, j - 1] == strong) or 
								(img[i - 1, j] == strong) or 
								(img[i - 1, j + 1] == strong)):  
								# c32 * (((M - 2) * (N - 2)) - Z)
									img[i, j] = strong  
									# c33 * (((M - 2) * 
									# (N - 2)) - Z - S)
								else:
									img[i, j] = 0   
									# c23 * (((M - 2) * 
									# (N - 2)) - Z - T)
							except IndexError as e:     
							# c24 * 0
								pass    # c25 * 0
				return img
		\end{python}
	
	\section{Laufzeiteffizienz eines Algorithmus}
	
	Nun wollen wir die Laufzeit des genannten Algorithmus betrachten. Hierzu zählen wir für eine gegebene Eingabe alle Anweisungen x mit einer Zeit t\tief{x}, welche von der Art von x abhängig ist. Folgende Annahmen setzen wir voraus: \nl
	
	\begin{itemize}
		\item Das Ausführen einer Zeile Code benötigt einen konstanten Zeitaufwand
		\item Verschiedene Zeilen (verschiedene Operationen) benötigen einen unterschiedlichen Zeitaufwand
	\end{itemize}
	
	Der benötigte, konstante Zeitaufwand, welchen eine Zeile z also benötigt, wird mit c\tief{x} bezeichnet.
	Im vorherigen Abschnitt ist in den Kommentaren des Python Codes bereits der jeweilige Zeitaufwand jeder Zeile vermerkt.
	Im Folgenden werden die Laufzeiten der einzelnen Funktionen sowie im Abschluss des gesamten Canny Algorithmus berechnet.\nl
	Zusätzlich betrachten wir - sofern möglich - den jeweils schlechtesten und besten Fall.\nl
	
	\pagebreak
	
		\subsection{Gauß Filter}

		Die Kosten für den Gauß Filter ergibt sich der Laufzeitaufwand hiermit zu: \nl
	
		\formelbox{ T(n)\tief{Gauß} = c\tief{1} + c\tief{2} + c\tief{3} + c\tief{4} }
		
		\nin Da wir hier jede Zeile einmal durchlaufen müssen ist der schlechteste Fall gleich dem besten Fall.

		\subsection{Sobel Filter}

		Der Sobel Filter hat ähnlich zum Gauß Filter einen geringen Laufzeitaufwand im Vergleich zum Gesamtaufwand:\nl
	
		\formelbox{ T(n)\tief{Sobel} = (c\tief{5} + c\tief{6}) * 2 + c\tief{7} + c\tief{8} + c\tief{9} }
			
		\nin Der Sobel Filter ist nur vom jeweiligen Eingangsbild abhängig, jede Zeile muss einmal durchlaufen werden. Je größer das Bild, desto größer auch der Rechenaufwand. Auch hier entspricht der schlechteste Fall gleich dem besten Fall.
	
		\subsection{Non Maximum Supression}
	
		Den größten Rechenaufwand beansprucht die Non Maximum Suppression. Hier ergibt sich der benötigte Laufzeitaufwand zu: \nl
	
		\formelbox{\parbox{0.4\textwidth}{
			\begin{center}
				T(n)\tief{nms} = c\tief{10} + c\tief{11} + c\tief{12} + c\tief{13} + c\tief{14} * (M - 2) + \\
				(c\tief{15} + c\tief{16} + 2 * c\tief{17} + c\tief{18} + 3 * c\tief{20} + c\tief{21} + \\
				c\tief{23}) * ((M - 2) * (N - 2)) + \\
				(2 * c\tief{19} - 9 * c\tief{20}) * A0 + \\
				(2 * c\tief{19} - 6 * c\tief{20}) * A45 + \\
				(2 * c\tief{19} - 3 * c\tief{20}) * A90 + \\
				c\tief{19} * 2 * A135 + \\ 
				(c\tief{22} - c\tief{23}) * Y
			\end{center}
		}}
		
		\subsection{Double threshold}
		
		Die double Threshold Methode beansprucht folgenden Laufzeitaufwand: \nl
	
		\formelbox{\parbox{0.4\textwidth}{
			\begin{center}
				T(n)\tief{double threshold} = c\tief{10} + c\tief{11} + 3 * c\tief{17} + \\
				c\tief{26} + c\tief{27} + 2 * c\tief{28} + c\tief{29} + 3 * c\tief{30}
			\end{center}
		}}
		
		\subsection{Hysterese}
	
		Letztendlich noch der Laufzeitaufwand der Hysterese mit: \nl
	
		\formelbox{\parbox{0.4\textwidth}{
			\begin{center}
				T(n)\tief{hysterese} = c\tief{10} + c\tief{14} * (M - 2) + \\
				(c\tief{15} + c\tief{16} + c\tief{23} + c\tief{31} + c\tief{32} + c\tief{33}) * ((M - 2) * (N - 2)) - \\
				Z * (c\tief{15} + c\tief{23} + c\tief{32} + c\tief{33}) - \\
				S * c\tief{33} - T * c\tief{23} \\
			\end{center}
		}}

		\pagebreak

		\subsection{Komplette Laufzeit}
		
		Die komplette Laufzeit T(n)\tief{Canny} des Algorithmus ergibt sich somit zu:
	
		\formelbox{\parbox{0.4\textwidth}{
			\begin{center}
				T(n)\tief{Canny} = \\
				c\tief{1} + c\tief{2} + c\tief{3} + c\tief{4} +	c\tief{5} * 2 + c\tief{6} * 2 + c\tief{7} + \\
				c\tief{8} + c\tief{9} + c\tief{10} * 3 + c\tief{11} * 2 + c\tief{12} + c\tief{13} + \\
				c\tief{14} * 2 * (M - 2) + c\tief{15} * (2 * ((M - 2) * (N - 2)) - Z) + \\
				c\tief{16} * 2 * ((M - 2) * (N - 2)) + c\tief{17} * 6 * ((M - 2) * (N - 2)) + \\
				c\tief{18} * ((M - 2) * (N - 2)) + \\
				c\tief{19} * 2 * (A0 + A45 + A90 + A135) + \\
				c\tief{20} * (-9 * A0 -6 * A45 -3 * A90 + 3 * ((M - 2) * (N - 2))) + \\
				c\tief{21} * ((M - 2) * (N - 2)) + c\tief{22} * Y + \\
				c\tief{23} * (2 * ((M - 2) * (N - 2)) - T - Y - Z) + \\
				c\tief{26} + c\tief{27} + c\tief{28} * 2 + c\tief{29} + c\tief{30} * 3 + \\
				c\tief{31} * ((M - 2) * (N - 2)) + c\tief{32} * (((M - 2) * (N - 2)) - Z) + \\
				c\tief{33} * (((M - 2) * (N - 2)) - Z - S) \\
			\end{center}
		}}
	
		Mit\nl
	 
		\formelbox{\parbox{0.3\textwidth}{
			\begin{center}
				A0 + A45 + A90 + A135 = ((M - 2) * (N - 2)); \\
				Z - T = S; \\
				Z - S = T; \\
				((M - 2) * (N - 2)) $\widehat{=}$ L; \\
			\end{center}
	
		}}

		kann man die Gleichung folgendermaßen vereinfachen:\nl

		\formelbox{\parbox{0.4\textwidth}{
			\begin{center}
				T(n)\tief{Canny} = \\
				c\tief{1} + c\tief{2} + c\tief{3} + c\tief{4} +	c\tief{5} * 2 + c\tief{6} * 2 + c\tief{7} + \\
				c\tief{8} + c\tief{9} + c\tief{10} * 3 + c\tief{11} * 2 + c\tief{12} + c\tief{13} + \\
				c\tief{14} * 2 * (M - 2) + c\tief{15} * (2 * L - Z) + \\
				c\tief{16} * 2 * L + c\tief{17} * 6 * L + c\tief{18} * L + \\
				c\tief{19} * 2 * L + c\tief{20} * (-9 * A0 -6 * A45 -3 * A90 + 3 * L) + \\
				c\tief{21} * L + c\tief{22} * Y + c\tief{23} * (2 * L - Y - S) + \\
				c\tief{26} + c\tief{27} + c\tief{28} * 2 + c\tief{29} + c\tief{30} * 3 + \\
				c\tief{31} * L + c\tief{32} * L - Z) + c\tief{33} * (L - T) \\
			\end{center}
		}}
	
		L hängt hierbei von der Größe des Eingangsbildes ab. Je größer das Eingangsbild, desto größer auch L und desto mehr Laufzeitaufwand ist nötig.
		
			\nlsubsubsection{Laufzeit im besten Fall}
			
			Im besten Fall (in welchem es trotzdem noch eine Kante im Bild gibt) kann man folgende Annahmen treffen:\nl
			
			\formelbox{\parbox{0.4\textwidth}{
					\begin{center}
						A45 = A90 = A135 = S = 0; \\
						A0 = Y = L; \\
						Z + T = L; \\
					\end{center}
			}}
		
			\formelbox{\parbox{0.4\textwidth}{
					\begin{center}
						T(n)\tief{Canny} = \\
						c\tief{1} + c\tief{2} + c\tief{3} + c\tief{4} +	c\tief{5} * 2 + c\tief{6} * 2 + c\tief{7} + \\
						c\tief{8} + c\tief{9} + c\tief{10} * 3 + c\tief{11} * 2 + c\tief{12} + c\tief{13} + \\
						c\tief{14} * 2 * (M - 2) + c\tief{15} * (2 * L - Z) + \\
						c\tief{16} * 2 * L + c\tief{17} * 6 * L + c\tief{18} * L + \\
						c\tief{19} * 2 * L + \\
						c\tief{21} * L + c\tief{22} * Y + \\
						c\tief{26} + c\tief{27} + c\tief{28} * 2 + c\tief{29} + c\tief{30} * 3 + \\
						c\tief{31} * L + c\tief{32} * (L - Z) + c\tief{33} * Z \\
					\end{center}
			}}	
		
			\nlsubsubsection{Lauftzeit im schlimmsten Fall}
			
			Analog können für den schlimmsten Fall folgende Annahmen getroffen werden:\nl
			
			\formelbox{\parbox{0.4\textwidth}{
				\begin{center}
					A0 = A45 = A90 = Y = Z = T = 0; \\
					S = L; \\
				\end{center}
			}}
		
			\formelbox{\parbox{0.4\textwidth}{
				\begin{center}
					T(n)\tief{Canny} = \\
					c\tief{1} + c\tief{2} + c\tief{3} + c\tief{4} +	c\tief{5} * 2 + c\tief{6} * 2 + c\tief{7} + \\
					c\tief{8} + c\tief{9} + c\tief{10} * 3 + c\tief{11} * 2 + c\tief{12} + c\tief{13} + \\
					c\tief{14} * 2 * (M - 2) + c\tief{15} * 2 * L + c\tief{16} * 2 * L + \\
					c\tief{17} * 6 * L + c\tief{18} * L + c\tief{19} * 2 * L + \\
					c\tief{20} * 3 * L + c\tief{21} * L + c\tief{23} * L + c\tief{26} + \\
					c\tief{27} + c\tief{28} * 2 + c\tief{29} + c\tief{30} * 3 + c\tief{31} * L + \\
					c\tief{32} * L + c\tief{33} * L \\
				\end{center}
			}}
	
	\section{Kantenerkennung mit dem Canny Algorithmus}
		
		Im folgenden sind die oben genannten Schritte des Canny Algorithmus einzeln in Python realisiert und auf ein Bild angewendet.		
	
		\subsection{Noise Reduction}
	
		Kantenerkennung ist sehr anfällig für Rauschen, da die meisten und ausschlaggebendsten mathematischen Operationen auf Ableitungen basieren. Deshalb muss eventuell vorhandenes Rauschen im ersten Schritt entfernt werden.
		Hierfür wir beim Canny Algorithmus das Bild mithilfe eines Gauß Filters geglättet. Mit einem Gaußschen Kernel (hier 5x5) wird der Intensitätswert an der Stelle (i,j) durch das gewichtete Mittel der ihn umgebenden Werte ersetzt.
		Der resultierende "blurring" Effekt hängt unmittelbar mit der Wahl der Kerngröße zusammen - je größer der Kern,  desto besser ist auch der blurring Effekt. Mit steigender Kerngröße steigt jedoch auch die benötigte Rechenzeit, weshalb man hier nur einen 5x5 Kern nimmt, um bei einem ausreichend guten Ergebnis noch performant zu sein.
		
		Hier auf das Logo der Hochschule Karlsruhe angewendet erkennt man im rechten Bild eine Unschärfe gegenüber dem linken Bild.
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.8\linewidth] {../Bilder/hochschule_blur_5_5}
			\caption{\textit{Links das original und rechts unter Anwendung des Gauß Filters.}}
		\end{figure}
		
		\subsection{Gradient Calculation}
		
		In diesem Schritt wird sowohl die Intensität als auch die Richtung der Kanten durch die Berechnung des Gradienten ermittelt. Eine Kante wird durch eine merkliche Änderung der Intensität benachbarter Pixel deutlich. Um eine Kante zu erkennen ist es also am einfachsten, einen Filter anzuwenden, welcher die Änderung der Intensität in horizontaler wie vertikaler Richtung markiert.
		
		Nach Glättung des Bildes werden nun also die Ableitungen in x (horizontaler) und y (vertikaler) Richtung berechnet. Am effizientesten kann man dies durch eine Faltung des Bildes mit einem Sobel Kern berechnen.
		
		Die Intensität und Richtung berechnen sich also zu \\
		
		\formelbox{|G| = $\sqrt{I\tief{x}\hoch{2} + I\tief{y}\hoch{2}}$}
		\medbreak
		\formelbox{$\Theta$(x,y) = arctan($\frac{I\tief{y}}{I\tief{x}})$}
		\medbreak
		Bereits nach diesem Schritt hat man schon ein ziemlich gutes Ergebnis in welchem das Ursprungsbild durch Kanten hinreichend dargestellt ist. 
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.5\linewidth] {../Bilder/sobel_after_blur}
			\caption{\textit{Bild nach Anwendung des Sobel Filters}}
		\end{figure}
		
		Man erkennt allerdings, dass die Kanten noch sehr unfein, grob und breit sind. Hier kommt der dritte Schritt ins Spiel, die Non-Maximum Suppression.
		
		\pagebreak
		
		\subsection{Non Maximum Suppression}
		
		Die momentan noch mehr als 1 Pixel breiten Kanten werden nun mit der sogenannten Non-Maximum Suppression Technik ausgedünnt. Hierbei wird jedes Pixel durchlaufen. Abhängig vom Gradienten, welcher uns die Richtung der Kante angibt, werden die Intensitätswerte der beiden Nachbarpixel des jeweiligen Pixels mit dem Intensitätswert des aktuellen Pixels verglichen. Ist einer der beiden Nachbarwerte größer, so wird der Grauwert des aktuellen Pixels auf Null gesetzt, andernfalls bleibt er unverändert. Nach einem erfolgreichen Durchlauf wurden alle Pixel entlang der Kante mit maximalen Intensitätswerten behalten. 
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.5\linewidth] {../Bilder/nms_after_sobel}
			\caption{\textit{Bild nach Anwendung der Non Maximum Suppression}}
		\end{figure}
		
		Man kann eine deutliche Ausdünnung der Kanten erkennen, ebenso ist ersichtlich, dass die Intensitätswerte der gefundenen Pixel Kanten noch stark variieren. Mit den folgenden 2 Schritten versuchen wir das so gut als möglich zu kompensieren und die Intensitätswerte zu vereinheitlichen.
		
		\subsection{Double threshold}
		
		Durch die double threshold Funktion markieren wir nun jedes bis jetzt als Kante markiertes Pixel als starkes oder schwaches Pixel und erhalten ein Bild mit nurnoch 3 verschiedenen Intensitätswerten, 255 (starkes Pixel), 25 (schwaches Pixel) und 0 (kein Kantenpixel).
	
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.5\linewidth] {../Bilder/double_threshold_after_nms}
			\caption{\textit{Bild mit starken (weiss) und schwachen (grau) Pixeln}}
		\end{figure}
	
		\subsection{Hysteresis}
		
		Zuletzt werden noch einmal alle Pixel geprüft und falls einer der direkten Nachbarn ein starkes Pixel ist, wird das aktuelle Pixel - falls es kein starkes Pixel ist - in ein starkes Pixel umgewandelt, indem der Intensitätswert auf 255 gesetzt wird.\nl
		Wenn ein Pixel kein starkes Pixel in der Nachbarschaft hat, wird sein Intensitätswert zu  0 gesetzt.
	
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.8\linewidth] {../Bilder/no_strong_pixel_around}
			\caption{\textit{Ein Pixel ohne starkes Pixel in der Nachbarschaft}}
		\end{figure}
	
		Hat ein Pixel ein starkes Pixel in der Nachbarschaft, wird sein Intensitätswert auf 255 gesetzt, es selbst zu einem starken Pixel.
	
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.8\linewidth] {../Bilder/one_strong_pixel_around}
			\caption{\textit{Ein Pixel mit einem starken Pixel in der Nachbarschaft}}
		\end{figure}
	
		Das Finale Bild mit den detektierten Kanten sieht nun folgendermaßen aus:
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.5\linewidth] {../Bilder/hysteresis_after_threshold}
			\caption{\textit{Finales Bild}}
		\end{figure}
	
	\section{Effizienzgewinn durch Kantenverfolgung}
	
		\subsection{Idee}
	
		Sobald eine Kante gefunden wurde ist es nicht mehr notwendig, jedes einzelne Pixel des kompletten Bildes zu überprüfen. Es soll der Kante gefolgt werden und auf dem Weg die entsprechenden Nachbarpixel der Kante zu 0 setzen und als "bearbeitet" markieren. So muss man nicht mehr jedes Pixel des Bildes untersuchen sondern erheblich weniger.\nl
		
		Sobald ein Kantenpixel gefunden wurde, werden - ähnlich zum Canny Algorithmus - die Nachbarn überprüft und der Gradient gebildet. So findet man das nächste Pixel der Kante. Das aktuelle Pixel erhält den Grauwert 255, den 7 übrigen Nachbarn wird der Intensitätswert 0 zugewiesen und der Algorithmus navigiert zum nächsten Pixel.\nl
		
		Dadurch, dass man - sobald eine Kante detektiert wurde - 7 Nachbarpixel auf 0 setzt und diese nicht erneut überprüfen muss ergibt sich ein nicht unerheblicher performance Gewinn mindestens des Faktors 7.\nl
		
		Dadurch, dass ein Bild im Schnitt nur zwischen 5\% und 10\% aus Kanten beseht, müssen diese zur Realisierung der Idee erst einmal detektiert werden.
		Hierzu gab es folgende Ansätze:\nl
		Man durchläuft beide Diagonalen des Bildes und folgt allen Kanten, welche man dort gefunden hat.
		Die Wahrscheinlichkeit, dass man durch diese Methode eine Kante findet, ist sehr hoch. Natürlich gibt es auch Bilder, welche keine Kanten auf den Diagonalen haben. Um hier nicht unnötige Laufzeit zu verschwenden, durchläuft man alle horizontalen, beginnend bei der ersten und dann immer im Abstand von 5 Pixeln. So durchläuft man nicht das komplette Bild und sollte definitiv eine Kante finden.
		
		Zur Berechnung der nächsten Richtung diente mir anfangs folgender Code:
		
		\begin{python}
			def direction(pos, img):
				direction = np.zeros((3, 3))
				direction[0][2] = abs(diagonal_top_right
									(pos, img) - diagonal_bottom_left
									(pos, img))
				direction[0][1] = abs(top(pos, img) - 
									bottom(pos, img))
				direction[0][0] = abs(diagonal_top_left
								(pos, img) - diagonal_bottom_right
								(pos, img))
				direction[1][0] = abs(left(pos, img) - 
									right(pos, img))
				direction[2][0] = value_raising_diagonal
									(pos, img)
				direction[2][1] = value_top_bottom
									(pos, img)
				direction[2][2] = value_falling_diagonal
									(pos, img)
				direction[1][2] = value_left_right
									(pos, img)
				
				return direction
		\end{python}
		
		\pagebreak
		
		Die Richtung (der Gradient) wurde dabei nach folgendem Algorithmus berechnet:
		
		\begin{python}
			def next_direction_to_move(current_position, 
										y, direct):
				if (direct[0] == 0) and (not all
				(k in forbidden_directions for k in 
				(1, 2, 3))):  # check for move up
					if (current_position[0] != 0) and 
					(1 not in forbidden_directions):  
					# check for top border
						moving_direction = 1
					elif (current_position[0] != 0) and 
					(2 not in forbidden_directions):  
					# check for top border
						moving_direction = 2
					elif (current_position[0] != 0) and 
					(3 not in forbidden_directions):  
					# check for top border
						moving_direction = 3
					elif (current_position[1] != 0) and 
					(4 not in forbidden_directions):  
					# move left cause we are at top border
						forbidden_directions.extend((1, 2, 3))
					moving_direction = 4
						elif 7 not in forbidden_directions:  
						# move down if left border
					moving_direction = 7
						forbidden_directions.
						extend((1, 2, 3, 4))
					else:
						print("no case for moving_direction 
						left")
						moving_direction = 9
				elif (direct[0] == 1) and (not all(k in 
				forbidden_directions for k in (4, 5))):  
				# check for left  or right
					if (direct[1] == 0) and 
					(current_position[1] != 0) and 
					(4 not in forbidden_directions):  
					# move right if left border
						moving_direction = 4
					elif 5 not in forbidden_directions:
						moving_direction = 5
						forbidden_directions.append(4)
					else:
						print("no case for moving_direction 
						left")
						moving_direction = 9
				else:  # move down cause no 
				case matches until now
					if (current_position[0] < y) and 
					(6 not in forbidden_directions):  
					# check for bottom border
						moving_direction = 6
					elif (current_position[0] < y) and 
					(7 not in forbidden_directions):  
					# check for bottom border
						moving_direction = 7
					elif (current_position[0] < y) and 
					(8 not in forbidden_directions):  
					# check for bottom border
						moving_direction = 8
					elif (current_position[1] != 0) and 
					(4 not in forbidden_directions):  
					# move left if bottom border
						moving_direction = 4
						forbidden_directions.
						extend((6, 7, 8))
					elif 5 not in forbidden_directions:  
					# move right when also at left border
						moving_direction = 5
						forbidden_directions.
						extend((4, 6, 7, 8))
					else:
						print("no case for moving_direction 
						left")
						moving_direction = 9
				
				return moving_direction
		\end{python}
	
		Ebenso war der Code zur Bestimmung des nächsten Pixels auf eine sehr triviale Weise vorhanden:
	
		\begin{python}
			def position_of_next_pixel(moving_direction, 
									current_position):
				if moving_direction == 1:
					next_pixel_position = 
					(current_position[0] - 1,
					 current_position[1] - 1)
				elif moving_direction == 2:
					next_pixel_position = 
					(current_position[0] - 1, 
					current_position[1])
				elif moving_direction == 3:
					next_pixel_position = 
					(current_position[0] - 1, 
					current_position[1] + 1)
				elif moving_direction == 4:
					next_pixel_position = 
					(current_position[0], 
					current_position[1] - 1)
				elif moving_direction == 5:
					next_pixel_position = 
					(current_position[0], 
					current_position[1] + 1)
				elif moving_direction == 6:
					next_pixel_position = 
					(current_position[0] + 1, 
					current_position[1] - 1)
				elif moving_direction == 7:
					next_pixel_position = 
					(current_position[0] + 1, 
					current_position[1])
				elif moving_direction == 8:
					next_pixel_position = 
					(current_position[0] + 1, 
					current_position[1] + 1)
				elif moving_direction == 9:
					print("no_next_pixel_position")
					next_pixel_position = 
					"moving in circles"
				
				return next_pixel_position
		\end{python}
	
		Hierbei traf ich auf das Problem, dass die Einsparung der Laufzeit durch direktes bearbeiten der Kantennachbarn sehr schnell wieder verloren geht und zwar dadurch, dass man mehrere Matrizen der Größe des Bildes benötigt um die einzelnen Stati wie neuer Grauwert, Richtung und ein \textit{bereits bearbeitet} Flag zu speichern. Diese muss man immer wieder abrufen, also die Matrizen laden, bearbeiten und verändert wieder abspeichern. Gerade bei größeren Bildern oder wenn eine Kante nicht mit dem Durchlaufen der Diagonalen gefunden wird, übersteigt die Laufzeit des geplanten Algorithmus die des Canny Algorithmus schnell.\nl
		Ebenso ist mit dem beschriebenen Vorgehen nicht sichergestellt, dass man alle Kanten findet. Um auch Objekte zum Beispiel am Rand zu finden müsste man das komplette Bild erneut mit einem Hysterese Algorithmus bearbeiten. \nl
		Trotz anfänglicher, guter Fortschritte hatte der geplante Algorithmus deshalb leider keine Aussicht auf Erfolg und eine Effizienzsteigerung des Canny Algorithmus durch Kantenverfolgung ist mit dieser Methode nicht möglich.
		
	\section{Laufzeitoptimierung des Canny Algorithmus}
	
	Ein schwarz-weiß Bild hat einige schwarze Pixel, also Pixel mit dem Intensitätswert 0. Der obige Canny prüft jedes Pixel viele Male. Einige dieser Cases kann man jedoch auslassen, da sie nicht geprüft werden müssen. So sind zum Beispiel Pixel mit einem Intensitätswert von 0 kein Teil einer Kante und man kann die Prüfung dieses Pixels überspringen.
	
	\section{Literaturverzeichnis}
		\begin{itemize}
			\item \textit{http://www9.in.tum.de/seminare/hs.SS06.EAMA/material/\\01\_ausarbeitung.pdf}
			\item \textit{https://www.kuppelwieser.net/index.php/technik/15-bildverarbeitung/40-canny-algorithmus}
			\item \textit{http://mi.informatik.uni-siegen.de/teaching/lectures/EI/\\script/10eiComplexity.pdf}
			\item \textit{https://edoc.sub.uni-hamburg.de/haw/volltexte/2016/3266/pdf/\\BA\_Tamou.pdf}
			\item \textit{https://en.wikipedia.org/wiki/Canny\_edge\_detector}
		\end{itemize}
\end{document}