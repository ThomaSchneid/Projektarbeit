\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage{float}
\usepackage{color}
\usepackage[T1]{fontenc}
\usepackage{xcolor}
%\usepackage{listings}
\usepackage{pythonhighlight}


%New commands
\newcommand{\tief}{\textsubscript}
\newcommand{\hoch}{\textsuperscript}
\newcommand{\nl}{\newline}
\newcommand{\formelbox}[1]{\centerline{\fbox{#1}}}

\begin{document}
	\title{Focus peaking - can edge detection improve the performance of current algorithms?}
	\author{Thomas Schneider \\ Matrikel-Nr: 60482 \\ Elektro- und Informationstechnik \\ Hochschule Karlsruhe}
	\onecolumn
	\maketitle
	\tableofcontents
	\twocolumn
	
	\section{Motivation/Einleitung}
	
	\begin{center}
		\textcolor{red}{\textbf{TODO}}
	\end{center}
	
	\section{Mathematische Grundlagen}

		\subsection{Gauß Filter}
	
		Der Gauß Filter ist ein linearer Filter, welcher in der Bildverarbeitung zur Glättung des Bildes und Verminderung von Rauschen, vor allem weißem,  verwendet. Feinere Strukturen des Bildes gehen hierbei verloren, wobei gröbere erhalten bleiben.
		Ein Gaußscher Filterkern der Größe (2k + 1)$\times$(2k + 1) kann mit
		\medbreak
		\formelbox{H\tief{ij} = $\frac{1}{2\pi\sigma\hoch{2}}$ * $\mathrm{e}$\hoch{-$\frac{(i - (k + 1))\hoch{2} + (j - (k + 1))\hoch{2}}{2\sigma\hoch{2}}$}}
		\medbreak
		berechnet werden. \nl
		In Python wird der Gauß Kern folgendermaßen realisiert:
		
		\begin{python}
			def gaussian_kernel(size, sigma=1):
				size = int(size) // 2
				x, y = np.mgrid[-size:size + 1,
								-size:size + 1]
				normal = 1 / (2.0 * np.pi * sigma ** 2)
				g = np.exp(-((x ** 2 + y ** 2) / 
							(2.0 * sigma ** 2))) * normal
				return g
		\end{python}		
	
		\subsection{Sobel Operator}
	
		Der Sobel Operator besteht aus zwei 3$\times$3 Faltungskernen, wobei ein Kern dem jeweils anderen um 90$\circ$ gedreht.
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.6\linewidth] {../Bilder/sobel_operator}
			\caption{\textit{Links der Faltungskern für die X- und rechts für die Y-Richtung.}}
		\end{figure}
	
		Für jedes Pixel werden die Komponenten der Matrix aufsummiert um den Grauwert zu erhalten.
		
		In Python realisieren wir den Sobel Filter folgendermaßen:
		
		\begin{python}
			def sobel_filter(img):
				Gx = np.array([[-1, 0, 1], [-2, 0, 2], 
							[-1, 0, 1]], np.float32)
				Gy = np.array([[1, 2, 1], [0, 0, 0],
							[-1, -2, -1]], np.float32)
		
				Ix = ndimage.filters.convolve(img, Gx)
				Iy = ndimage.filters.convolve(img, Gy)
		
				G = np.hypot(Ix, Iy)
				G = G / G.max() * 255
				theta = np.arctan(Iy, Ix)
		
				return G, theta
		\end{python}
	
		\subsection{Non Maximum Suppression}
	
		Die Non Maximum Suppression Technik wird angewendet um bereits gefundene Intensitätsmaxima (Kanten) erneut zu prüfen und diese auszudünnen. Hierfür durchläuft der Algorithmus jedes gefundene Kantenpixel und vergleicht, basierend auf dem Gradienten des jeweiligen Pixels, die entsprechenden Nachbarpixel. Sollte eines der Nachbarpixel einen höheren Grauwert als das aktuelle Pixel aufweisen, wird der Grauwert des aktuellen Pixels auf 0 gesetzt. Bildlich kann man sich die Technik folgendermaßen vorstellen
	
		\begin{figure}[H]
			\centering
			\includegraphics[width=1\linewidth] {../Bilder/nms_how_to}
			\caption{\textit{Darstellung der Non Maximum Suppression Technik}}
		\end{figure}

		Schauen wir uns nun das untere, rot umrahmte Pixel etwas genauer an. Die Richtung der Kante wird hier durch den blauen Pfeil symbolisiert und und entspricht einem Winkel von $\frac{\pi}{2}$ (90°).
	
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.7\linewidth] {../Bilder/nms_inspect_pixel}
			\caption{\textit{Nähere Betrachtung eines einzigen Pixels}}
		\end{figure}
	
		Die Richtung der Kante wird durch den grünen Pfeil dargestellt und verläuft vertikal von oben nach unten. Der Algorithmus prüft nun, ob die Pixel ober- und unterhalb (im Bild blau markiert) des ausgewählten Pixels (rot im Bild markiert) einen höheren Intensitätswert aufweisen. In unserem Beispiel ist der Intensitätswert des unteren Pixels (i + 1, j) höher als der der anderen Beiden (das untere Pixel hat einen Intensitätswert von 255, da es weiß ist). Der Intensitätswert des aktuellen Pixels wird nun auf 0 gesetzt. Hätte keines der beiden anderen Pixel einen höheren Intensitätswert, würde der aktuelle Wert beibehalten werden.\nl
		Jedes Pixel hat also 2 Hauptkriterien, die Gradientenrichtung und den Intensitätswert. Die Non Maximum Suppression nutzt diese beiden Merkmale und führt folgende Schritte durch:
	
		\begin{itemize}
			\item Eine Matrix mit nullen der gleichen Größe der Gradientenmatrix erstellen
			\item Kantenrichtung anhand der Gradientenmatrix erkennen
			\item Prüfen ob Pixel entlang der Kantenrichtung einen höheren Intensitätswert als das aktuelle Pixel haben
			\item Das mit dem Non Maximum Suppression Algorithmus bearbeitete Bild zurückgeben
		\end{itemize}

		Den Non Maximum Suppression Algorithmus realisieren wir durch folgenden Python Code:
	
		\begin{python}
			def non_max_suppression(img, D):
				M, N = img.shape
				Z = np.zeros((M, N))
				angle = D * 180. / np.pi
				angle[angle < 0] += 180
		
				for i in range(1, M - 1):
					for j in range(1, N - 1):
						try:
							q = 255
							r = 255
		
							# angle 0
							if (0 <= angle[i, j] < 22.5) or 
							   (157.5 <= angle[i, j] <= 180):
								q = img[i, j + 1]
								r = img[i, j - 1]
							# angle 45
							elif 22.5 <= angle[i, j] < 67.5:
								q = img[i + 1, j - 1]
								r = img[i - 1, j + 1]
							# angle 90
							elif 67.5 <= angle[i, j] < 112.5:
								q = img[i + 1, j]
								r = img[i - 1, j]
							# angle 135
							elif 112.5 <= angle[i, j] < 157.5:
								q = img[i - 1, j - 1]
								r = img[i + 1, j + 1]
		
							if (img[i, j] >= q) and
						   	   (img[i, j] >= r):
								Z[i, j] = img[i, j]
							else:
								Z[i, j] = 0
		
						except IndexError as e:
							pass
				return Z
		\end{python}
	
		\subsection{Double threshold}
	
		Der double threshold Filter unterteilt unser Bild in 3 Arten von Pixeln
	
		\begin{itemize}
			\item \textbf{Starke Pixel}
			\begin{itemize}
				\item Pixel, deren Intensitätswert hoch genug ist, dass wir uns sicher sein können, dass sie ein Teil der finalen Kante sind.
			\end{itemize}
			\item \textbf{Schwache Pixel}
			\begin{itemize}
				\item Pixel, deren Intensitätswert nicht hoch genug ist um als starkes Pixel eingestuft zu werden, allerdings hoch genug ist um nicht als unsignifikant für die Kantenerkennung zu sein.
			\end{itemize}
			\item \textbf{Andere Pixel}
			\begin{itemize}
				\item Alle Pixel, welche keine der anderen beiden Bedingungen erfüllen.
			\end{itemize}
		\end{itemize}

		Es wird eine Obergrenze (high threshold) und eine Untergrenze (low threshold) für die Intensitätswerte festgelegt. Ist der Intensitätswert eines Pixels höher als oder gleich der Obergrenze, wird es als starkes Pixel markiert, der Intensitätswert also auf 255 gesetzt. Befindet sich der Intensitätswert des Pixels zwischen Ober- und Untergrenze, wird es als schwaches Pixel markiert. Sollte der Intensitätswert des Pixels kleiner als die Untergrenze sein, wird er auf 0 gesetzt. \nl
		Die beiden Schwellenwerte werden abhängig vom Eingangsbild berechnet, in unserem Beispiel durch den Faktor 0.05 für die untere und 0.09 für die obere Schwelle. In Python setzen wir die double threshold Funktion folgendermaßen um:
	
		\begin{python}
			def double_threshold(img, lowRatio=0.05, 
								 highRatio=0.09):
				highThreshold = img.max() * highRatio
				lowThreshold = highThreshold * lowRatio
			
				M, N = img.shape
				res = np.zeros((M, N))
			
				strong = np.int32(255)
				weak = np.int32(25)
				zero = np.int32(0)
			
				strong_i, strong_j = np.
							where(img >= highThreshold)
				zeros_i, zeros_j = np.
							where(img < lowThreshold)
				weak_i, weak_j = np.
						where((img <= highThreshold) & 
							  (img >= lowThreshold))
			
				res[strong_i, strong_j] = strong
				res[weak_i, weak_j] = weak
				res[zeros_i, zeros_j] = zero
			
				return res
		\end{python}

		\subsection{Kantenverfolgung durch Hysterese}
		
		Durch eine Hysterese wird festgelegt, ab welcher Kantenstärke ein Pixel zu einer Kante gehört. Mithilfe zweier Schwellwerte T\tief{1} < T\tief{2} wird jedes Pixel eines Bildes überprüft. Sobald ein Pixel einen Intensitätswert über T\tief{2} hat, wird diesem Pixel gefolgt und jedes Pixel entlang der so gefundenen Kante, dessen Intensitätswert größer T\tief{1} ist, als Element dieser Kante markiert.
		
		Wir realisieren unsere Hysterese Funktion in Python folgendermaßen:
		
		\begin{python}
			def hysteresis(img, weak, strong=255):
				M, N = img.shape
				for i in range(1, M - 1):
					for j in range(1, N - 1):
						if img[i, j] == weak:
							try:
								if ((img[i + 1, j - 1] == strong) or 
									(img[i + 1, j] == strong) or 
									(img[i + 1, j + 1] == strong) or 
									(img[i, j - 1] == strong) or 
									(img[i, j + 1] == strong) or 
									(img[i - 1, j - 1] == strong) or 
									(img[i - 1, j] == strong) or 
									(img[i - 1, j + 1] == strong)):
									img[i, j] = strong
								else:
									img[i, j] = 0
							
							except IndexError as e:
								pass
				
				return img
			
		\end{python}
	
		\section{How to measure performance of algorithms}
		
		\begin{center}
			\textcolor{red}{\textbf{TODO}}
		\end{center}
	
	\section{Canny Edge Detection}
	
		Der Canny Algorithmus lässt sich in folgende 5 Schritte unterteilen:
	
		\begin{enumerate}
			\item Noise reduction
			\item Gradient calculation
			\item Non-maximum suppression
			\item Double treshold
			\item Edge Tracking by Hysteresis
		\end{enumerate}
	
		\subsection{Noise Reduction}
	
		Kantenerkennung ist sehr anfällig für Rauschen, da die meisten und ausschlaggebendsten mathematischen Operationen auf Ableitungen basieren. Deshalb muss eventuell vorhandenes Rauschen im ersten Schritt entfernt werden.
		Hierfür wir beim Canny Algorithmus das Bild mithilfe eines Gauß Filters geglättet. Mit einem Gaußschen Kernel (hier 5x5) wird der Intensitätswert an der Stelle (i,j) durch das gewichtete Mittel der ihn umgebenden Werte ersetzt.
		Der resultierende "blurring" Effekt hängt unmittelbar mit der Wahl der Kerngröße zusammen - je größer der Kern,  desto besser ist auch der blurring Effekt. Mit steigender Kerngröße steigt jedoch auch die benötigte Rechenzeit, weshalb man hier nur einen 5x5 Kern nimmt, um bei einem ausreichend guten Ergebnis noch performant zu sein.
		
		Hier auf das Logo der Hochschule Karlsruhe angewendet erkennt man im rechten Bild eine Unschärfe gegenüber dem linken Bild.
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.8\linewidth] {../Bilder/hochschule_blur_5_5}
			\caption{\textit{Links das original und rechts unter Anwendung des Gauß Filters.}}
		\end{figure}
		
		\subsection{Gradient Calculation}
		
		In diesem Schritt wird sowohl die Intensität als auch die Richtung der Kanten durch die Berechnung des Gradienten ermittelt. Eine Kante wird durch eine merkliche Änderung der Intensität benachbarter Pixel deutlich. Um eine Kante zu erkennen ist es also am einfachsten, einen Filter anzuwenden, welcher die Änderung der Intensität in horizontaler wie vertikaler Richtung markiert.
		
		Nach Glättung des Bildes werden nun also die Ableitungen in x (horizontaler) und y (vertikaler) Richtung berechnet. Am effizientesten kann man dies durch eine Faltung des Bildes mit einem Sobel Kern berechnen.
		
		Die Intensität und Richtung berechnen sich also zu \\
		
		\formelbox{|G| = $\sqrt{I\tief{x}\hoch{2} + I\tief{y}\hoch{2}}$}
		\medbreak
		\formelbox{$\Theta$(x,y) = arctan($\frac{I\tief{y}}{I\tief{x}})$}
		\medbreak
		Bereits nach diesem Schritt hat man schon ein ziemlich gutes Ergebnis in welchem das Ursprungsbild durch Kanten hinreichend dargestellt ist. 
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.5\linewidth] {../Bilder/sobel_after_blur}
			\caption{\textit{Bild nach Anwendung des Sobel Filters}}
		\end{figure}
		
		Man erkennt allerdings, dass die Kanten noch sehr unfein, grob und breit sind. Hier kommt der dritte Schritt ins Spiel, die Non-Maximum Suppression.
		
		\subsection{Non Maximum Suppression}
		
		Die momentan noch mehr als 1 Pixel breiten Kanten werden nun mit der sogenannten Non-Maximum Suppression Technik ausgedünnt. Hierbei wird jedes Pixel durchlaufen. Abhängig vom Gradienten, welcher uns die Richtung der Kante angibt, werden die Intensitätswerte der beiden Nachbarpixel des jeweiligen Pixels mit dem Intensitätswert des aktuellen Pixels verglichen. Ist einer der beiden Nachbarwerte größer, so wird der Grauwert des aktuellen Pixels auf Null gesetzt, andernfalls bleibt er unverändert. Nach einem erfolgreichen Durchlauf wurden alle Pixel entlang der Kante mit maximalen Intensitätswerten behalten. 
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.5\linewidth] {../Bilder/nms_after_sobel}
			\caption{\textit{Bild nach Anwendung der Non Maximum Suppression}}
		\end{figure}
		
		Man kann eine deutliche Ausdünnung der Kanten erkennen, ebenso ist ersichtlich, dass die Intensitätswerte der gefundenen Pixel Kanten noch stark variieren. Mit den folgenden 2 Schritten versuchen wir das so gut als möglich zu kompensieren und die Intensitätswerte zu vereinheitlichen.
		
		\subsection{Double threshold}
		
		Durch die double threshold Funktion markieren wir nun jedes bis jetzt als Kante markiertes Pixel als starkes oder schwaches Pixel und erhalten ein Bild mit nurnoch 3 verschiedenen Intensitätswerten, 255 (starkes Pixel), 25 (schwaches Pixel) und 0 (kein Kantenpixel).
	
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.5\linewidth] {../Bilder/double_threshold_after_nms}
			\caption{\textit{Bild mit starken (weiss) und schwachen (grau) Pixeln}}
		\end{figure}
	
		\subsection{Hysteresis}
		
		Zuletzt werden noch einmal alle Pixel geprüft und falls einer der direkten Nachbarn ein starkes Pixel ist, wird das aktuelle Pixel - falls es kein starkes Pixel ist - in ein starkes Pixel umgewandelt, indem der Intensitätswert auf 255 gesetzt wird.\nl
		Wenn ein Pixel kein starkes Pixel in der Nachbarschaft hat, wird sein Intensitätswert zu  0 gesetzt.
	
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.8\linewidth] {../Bilder/no_strong_pixel_around}
			\caption{\textit{Ein Pixel ohne starkes Pixel in der Nachbarschaft}}
		\end{figure}
	
		Hat ein Pixel ein starkes Pixel in der Nachbarschaft, wird sein Intensitätswert auf 255 gesetzt, es selbst zu einem starken Pixel.
	
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.8\linewidth] {../Bilder/one_strong_pixel_around}
			\caption{\textit{Ein Pixel mit einem starken Pixel in der Nachbarschaft}}
		\end{figure}
	\section{Effizienzgewinn durch Kantenverfolgung}
	
	\begin{center}
		\textcolor{red}{\textbf{TODO}}
	\end{center}
	
\end{document}